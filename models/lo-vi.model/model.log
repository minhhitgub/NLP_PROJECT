[Fri, 16 May 2025 23:01:36 INFO] .lo * src vocab size = 9485
[Fri, 16 May 2025 23:01:36 INFO] .vi * tgt vocab size = 8376
[Fri, 16 May 2025 23:01:36 INFO] Building model...
[Fri, 16 May 2025 23:01:37 INFO] Transformer(
  (encoder): Encoder(
    (embed): Embedding(9485, 256)
    (pe): PositionalEncoder(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (layers): ModuleList(
      (0-3): 4 x EncoderLayer(
        (norm_1): Norm()
        (norm_2): Norm()
        (attn): MultiHeadAttention(
          (q_linear): Linear(in_features=256, out_features=256, bias=True)
          (k_linear): Linear(in_features=256, out_features=256, bias=True)
          (v_linear): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (out): Linear(in_features=256, out_features=256, bias=True)
        )
        (ff): FeedForward(
          (linear_1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (dropout_1): Dropout(p=0.1, inplace=False)
        (dropout_2): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): Norm()
  )
  (decoder): Decoder(
    (embed): Embedding(8376, 256)
    (pe): PositionalEncoder(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (layers): ModuleList(
      (0-3): 4 x DecoderLayer(
        (norm_1): Norm()
        (norm_2): Norm()
        (norm_3): Norm()
        (dropout_1): Dropout(p=0.1, inplace=False)
        (dropout_2): Dropout(p=0.1, inplace=False)
        (dropout_3): Dropout(p=0.1, inplace=False)
        (attn_1): MultiHeadAttention(
          (q_linear): Linear(in_features=256, out_features=256, bias=True)
          (k_linear): Linear(in_features=256, out_features=256, bias=True)
          (v_linear): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (out): Linear(in_features=256, out_features=256, bias=True)
        )
        (attn_2): MultiHeadAttention(
          (q_linear): Linear(in_features=256, out_features=256, bias=True)
          (k_linear): Linear(in_features=256, out_features=256, bias=True)
          (v_linear): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (out): Linear(in_features=256, out_features=256, bias=True)
        )
        (ff): FeedForward(
          (linear_1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_2): Linear(in_features=2048, out_features=256, bias=True)
        )
      )
    )
    (norm): Norm()
  )
  (out): Linear(in_features=256, out_features=8376, bias=True)
)
[Fri, 16 May 2025 23:01:37 INFO] Encoder: 7688960
[Fri, 16 May 2025 23:01:37 INFO] Decoder: 8459776
[Fri, 16 May 2025 23:01:37 INFO] * Number of parameters: 16148736
[Fri, 16 May 2025 23:01:37 INFO] Starting training on cuda
[Fri, 16 May 2025 23:01:56 INFO] epoch: 003 - iter: 00200 - train loss: 1.0258 - time elapsed/per batch: 19.0441 0.0952
[Fri, 16 May 2025 23:02:16 INFO] epoch: 003 - iter: 00400 - train loss: 1.0320 - time elapsed/per batch: 19.1774 0.0959
[Fri, 16 May 2025 23:02:33 INFO] epoch: 003 - iter: 00600 - train loss: 0.9976 - time elapsed/per batch: 17.1498 0.0857
[Fri, 16 May 2025 23:02:51 INFO] epoch: 003 - iter: 00800 - train loss: 1.0468 - time elapsed/per batch: 18.1613 0.0908
[Fri, 16 May 2025 23:03:08 INFO] epoch: 003 - iter: 01000 - train loss: 1.0257 - time elapsed/per batch: 17.5773 0.0879
[Fri, 16 May 2025 23:03:26 INFO] epoch: 003 - iter: 01200 - train loss: 1.0454 - time elapsed/per batch: 17.4487 0.0872
[Fri, 16 May 2025 23:03:44 INFO] epoch: 003 - iter: 01400 - train loss: 0.9998 - time elapsed/per batch: 17.9927 0.0900
[Fri, 16 May 2025 23:04:00 INFO] epoch: 003 - iter: 01600 - train loss: 1.0467 - time elapsed/per batch: 15.8257 0.0791
[Fri, 16 May 2025 23:04:18 INFO] epoch: 003 - iter: 01800 - train loss: 1.0118 - time elapsed/per batch: 18.0653 0.0903
[Fri, 16 May 2025 23:04:36 INFO] epoch: 003 - iter: 02000 - train loss: 0.9918 - time elapsed/per batch: 18.5557 0.0928
[Fri, 16 May 2025 23:04:52 INFO] epoch: 003 - iter: 02200 - train loss: 1.0421 - time elapsed/per batch: 15.9528 0.0798
[Fri, 16 May 2025 23:05:10 INFO] epoch: 003 - iter: 02400 - train loss: 1.0266 - time elapsed/per batch: 17.4859 0.0874
[Fri, 16 May 2025 23:05:24 INFO] epoch: 003 - iter: 02600 - train loss: 1.0401 - time elapsed/per batch: 14.6124 0.0731
[Fri, 16 May 2025 23:05:40 INFO] epoch: 003 - iter: 02800 - train loss: 1.0249 - time elapsed/per batch: 15.3304 0.0767
[Fri, 16 May 2025 23:05:57 INFO] epoch: 003 - iter: 03000 - train loss: 1.0053 - time elapsed/per batch: 17.2544 0.0863
[Fri, 16 May 2025 23:06:47 INFO] epoch: 003 - iter: 03124 - valid loss: 3.7409 - bleu score: 0.0549 - full evaluation time: 39.7427
[Fri, 16 May 2025 23:07:04 INFO] epoch: 004 - iter: 00200 - train loss: 0.9901 - time elapsed/per batch: 17.0020 0.0850
[Fri, 16 May 2025 23:07:21 INFO] epoch: 004 - iter: 00400 - train loss: 1.0152 - time elapsed/per batch: 16.7332 0.0837
[Fri, 16 May 2025 23:07:36 INFO] epoch: 004 - iter: 00600 - train loss: 1.0287 - time elapsed/per batch: 15.1485 0.0757
[Fri, 16 May 2025 23:07:55 INFO] epoch: 004 - iter: 00800 - train loss: 0.9829 - time elapsed/per batch: 19.2264 0.0961
[Fri, 16 May 2025 23:08:11 INFO] epoch: 004 - iter: 01000 - train loss: 1.0192 - time elapsed/per batch: 16.0783 0.0804
[Fri, 16 May 2025 23:08:27 INFO] epoch: 004 - iter: 01200 - train loss: 1.0079 - time elapsed/per batch: 16.0447 0.0802
[Fri, 16 May 2025 23:08:44 INFO] epoch: 004 - iter: 01400 - train loss: 0.9747 - time elapsed/per batch: 16.4500 0.0823
[Fri, 16 May 2025 23:09:02 INFO] epoch: 004 - iter: 01600 - train loss: 0.9976 - time elapsed/per batch: 17.9272 0.0896
[Fri, 16 May 2025 23:09:20 INFO] epoch: 004 - iter: 01800 - train loss: 0.9866 - time elapsed/per batch: 18.8924 0.0945
[Fri, 16 May 2025 23:09:38 INFO] epoch: 004 - iter: 02000 - train loss: 0.9588 - time elapsed/per batch: 17.4282 0.0871
[Fri, 16 May 2025 23:09:57 INFO] epoch: 004 - iter: 02200 - train loss: 0.9992 - time elapsed/per batch: 18.7455 0.0937
[Fri, 16 May 2025 23:10:14 INFO] epoch: 004 - iter: 02400 - train loss: 0.9765 - time elapsed/per batch: 17.4953 0.0875
[Fri, 16 May 2025 23:10:31 INFO] epoch: 004 - iter: 02600 - train loss: 0.9946 - time elapsed/per batch: 16.9747 0.0849
[Fri, 16 May 2025 23:10:48 INFO] epoch: 004 - iter: 02800 - train loss: 0.9848 - time elapsed/per batch: 16.8283 0.0841
[Fri, 16 May 2025 23:11:06 INFO] epoch: 004 - iter: 03000 - train loss: 0.9773 - time elapsed/per batch: 17.6743 0.0884
[Fri, 16 May 2025 23:11:55 INFO] epoch: 004 - iter: 03124 - valid loss: 3.5662 - bleu score: 0.0774 - full evaluation time: 39.7172
[Fri, 16 May 2025 23:12:12 INFO] epoch: 005 - iter: 00200 - train loss: 0.9582 - time elapsed/per batch: 17.1490 0.0857
[Fri, 16 May 2025 23:12:29 INFO] epoch: 005 - iter: 00400 - train loss: 0.9438 - time elapsed/per batch: 17.0840 0.0854
[Fri, 16 May 2025 23:12:45 INFO] epoch: 005 - iter: 00600 - train loss: 0.9537 - time elapsed/per batch: 15.1120 0.0756
[Fri, 16 May 2025 23:13:01 INFO] epoch: 005 - iter: 00800 - train loss: 0.9626 - time elapsed/per batch: 16.7680 0.0838
[Fri, 16 May 2025 23:13:17 INFO] epoch: 005 - iter: 01000 - train loss: 0.9834 - time elapsed/per batch: 15.8982 0.0795
[Fri, 16 May 2025 23:13:33 INFO] epoch: 005 - iter: 01200 - train loss: 0.9290 - time elapsed/per batch: 16.0432 0.0802
[Fri, 16 May 2025 23:13:52 INFO] epoch: 005 - iter: 01400 - train loss: 0.9579 - time elapsed/per batch: 18.7401 0.0937
[Fri, 16 May 2025 23:14:09 INFO] epoch: 005 - iter: 01600 - train loss: 0.9491 - time elapsed/per batch: 16.7061 0.0835
[Fri, 16 May 2025 23:14:26 INFO] epoch: 005 - iter: 01800 - train loss: 0.9762 - time elapsed/per batch: 16.8614 0.0843
[Fri, 16 May 2025 23:14:44 INFO] epoch: 005 - iter: 02000 - train loss: 0.9433 - time elapsed/per batch: 18.5603 0.0928
[Fri, 16 May 2025 23:15:00 INFO] epoch: 005 - iter: 02200 - train loss: 0.9710 - time elapsed/per batch: 15.6540 0.0783
[Fri, 16 May 2025 23:15:17 INFO] epoch: 005 - iter: 02400 - train loss: 0.9792 - time elapsed/per batch: 17.4003 0.0870
[Fri, 16 May 2025 23:15:34 INFO] epoch: 005 - iter: 02600 - train loss: 0.9600 - time elapsed/per batch: 16.6762 0.0834
[Fri, 16 May 2025 23:15:52 INFO] epoch: 005 - iter: 02800 - train loss: 0.9357 - time elapsed/per batch: 18.5933 0.0930
[Fri, 16 May 2025 23:16:11 INFO] epoch: 005 - iter: 03000 - train loss: 0.9460 - time elapsed/per batch: 18.4658 0.0923
[Fri, 16 May 2025 23:17:02 INFO] epoch: 005 - iter: 03124 - valid loss: 3.4258 - bleu score: 0.1000 - full evaluation time: 38.9827
[Fri, 16 May 2025 23:17:20 INFO] epoch: 006 - iter: 00200 - train loss: 0.8942 - time elapsed/per batch: 17.4772 0.0874
[Fri, 16 May 2025 23:17:38 INFO] epoch: 006 - iter: 00400 - train loss: 0.9590 - time elapsed/per batch: 18.2923 0.0915
[Fri, 16 May 2025 23:17:55 INFO] epoch: 006 - iter: 00600 - train loss: 0.8904 - time elapsed/per batch: 17.2436 0.0862
[Fri, 16 May 2025 23:18:10 INFO] epoch: 006 - iter: 00800 - train loss: 0.9303 - time elapsed/per batch: 14.8089 0.0740
[Fri, 16 May 2025 23:18:26 INFO] epoch: 006 - iter: 01000 - train loss: 0.9420 - time elapsed/per batch: 15.5236 0.0776
[Fri, 16 May 2025 23:18:42 INFO] epoch: 006 - iter: 01200 - train loss: 0.9291 - time elapsed/per batch: 16.3107 0.0816
[Fri, 16 May 2025 23:18:58 INFO] epoch: 006 - iter: 01400 - train loss: 0.9070 - time elapsed/per batch: 16.3285 0.0816
[Fri, 16 May 2025 23:19:16 INFO] epoch: 006 - iter: 01600 - train loss: 0.8865 - time elapsed/per batch: 18.0080 0.0900
[Fri, 16 May 2025 23:19:35 INFO] epoch: 006 - iter: 01800 - train loss: 0.9011 - time elapsed/per batch: 18.3801 0.0919
[Fri, 16 May 2025 23:19:53 INFO] epoch: 006 - iter: 02000 - train loss: 0.9031 - time elapsed/per batch: 18.0225 0.0901
[Fri, 16 May 2025 23:20:10 INFO] epoch: 006 - iter: 02200 - train loss: 0.8914 - time elapsed/per batch: 17.2727 0.0864
[Fri, 16 May 2025 23:20:29 INFO] epoch: 006 - iter: 02400 - train loss: 0.8879 - time elapsed/per batch: 18.7675 0.0938
[Fri, 16 May 2025 23:20:47 INFO] epoch: 006 - iter: 02600 - train loss: 0.8943 - time elapsed/per batch: 17.9227 0.0896
[Fri, 16 May 2025 23:21:04 INFO] epoch: 006 - iter: 02800 - train loss: 0.8895 - time elapsed/per batch: 17.0690 0.0853
[Fri, 16 May 2025 23:21:21 INFO] epoch: 006 - iter: 03000 - train loss: 0.8920 - time elapsed/per batch: 17.6447 0.0882
[Fri, 16 May 2025 23:22:12 INFO] epoch: 006 - iter: 03124 - valid loss: 3.3132 - bleu score: 0.1223 - full evaluation time: 40.2984
[Fri, 16 May 2025 23:22:30 INFO] epoch: 007 - iter: 00200 - train loss: 0.9048 - time elapsed/per batch: 18.1479 0.0907
[Fri, 16 May 2025 23:22:46 INFO] epoch: 007 - iter: 00400 - train loss: 0.9019 - time elapsed/per batch: 16.1735 0.0809
[Fri, 16 May 2025 23:23:03 INFO] epoch: 007 - iter: 00600 - train loss: 0.8791 - time elapsed/per batch: 17.2100 0.0861
[Fri, 16 May 2025 23:23:21 INFO] epoch: 007 - iter: 00800 - train loss: 0.8623 - time elapsed/per batch: 17.6100 0.0881
[Fri, 16 May 2025 23:23:41 INFO] epoch: 007 - iter: 01000 - train loss: 0.8611 - time elapsed/per batch: 19.6990 0.0985
[Fri, 16 May 2025 23:23:57 INFO] epoch: 007 - iter: 01200 - train loss: 0.8789 - time elapsed/per batch: 16.5090 0.0825
[Fri, 16 May 2025 23:24:14 INFO] epoch: 007 - iter: 01400 - train loss: 0.8885 - time elapsed/per batch: 16.6500 0.0833
[Fri, 16 May 2025 23:24:31 INFO] epoch: 007 - iter: 01600 - train loss: 0.8812 - time elapsed/per batch: 17.2636 0.0863
[Fri, 16 May 2025 23:24:47 INFO] epoch: 007 - iter: 01800 - train loss: 0.8925 - time elapsed/per batch: 16.2380 0.0812
[Fri, 16 May 2025 23:25:04 INFO] epoch: 007 - iter: 02000 - train loss: 0.8771 - time elapsed/per batch: 16.7035 0.0835
[Fri, 16 May 2025 23:25:19 INFO] epoch: 007 - iter: 02200 - train loss: 0.9002 - time elapsed/per batch: 15.1285 0.0756
[Fri, 16 May 2025 23:25:37 INFO] epoch: 007 - iter: 02400 - train loss: 0.8979 - time elapsed/per batch: 18.0955 0.0905
[Fri, 16 May 2025 23:25:57 INFO] epoch: 007 - iter: 02600 - train loss: 0.8840 - time elapsed/per batch: 19.6915 0.0985
[Fri, 16 May 2025 23:26:14 INFO] epoch: 007 - iter: 02800 - train loss: 0.8679 - time elapsed/per batch: 17.1390 0.0857
[Fri, 16 May 2025 23:26:31 INFO] epoch: 007 - iter: 03000 - train loss: 0.8925 - time elapsed/per batch: 17.3680 0.0868
[Fri, 16 May 2025 23:27:20 INFO] epoch: 007 - iter: 03124 - valid loss: 3.2491 - bleu score: 0.1376 - full evaluation time: 38.3455
[Fri, 16 May 2025 23:27:38 INFO] epoch: 008 - iter: 00200 - train loss: 0.8682 - time elapsed/per batch: 18.2695 0.0913
[Fri, 16 May 2025 23:27:55 INFO] epoch: 008 - iter: 00400 - train loss: 0.8787 - time elapsed/per batch: 16.8790 0.0844
[Fri, 16 May 2025 23:28:11 INFO] epoch: 008 - iter: 00600 - train loss: 0.8643 - time elapsed/per batch: 16.3120 0.0816
[Fri, 16 May 2025 23:28:27 INFO] epoch: 008 - iter: 00800 - train loss: 0.8492 - time elapsed/per batch: 16.0760 0.0804
[Fri, 16 May 2025 23:28:43 INFO] epoch: 008 - iter: 01000 - train loss: 0.9085 - time elapsed/per batch: 16.0830 0.0804
[Fri, 16 May 2025 23:28:58 INFO] epoch: 008 - iter: 01200 - train loss: 0.8740 - time elapsed/per batch: 14.5835 0.0729
[Fri, 16 May 2025 23:29:15 INFO] epoch: 008 - iter: 01400 - train loss: 0.8512 - time elapsed/per batch: 17.2430 0.0862
[Fri, 16 May 2025 23:29:32 INFO] epoch: 008 - iter: 01600 - train loss: 0.8774 - time elapsed/per batch: 16.9020 0.0845
[Fri, 16 May 2025 23:29:49 INFO] epoch: 008 - iter: 01800 - train loss: 0.8781 - time elapsed/per batch: 17.1195 0.0856
[Fri, 16 May 2025 23:30:09 INFO] epoch: 008 - iter: 02000 - train loss: 0.8460 - time elapsed/per batch: 19.7060 0.0985
[Fri, 16 May 2025 23:30:27 INFO] epoch: 008 - iter: 02200 - train loss: 0.8601 - time elapsed/per batch: 18.3260 0.0916
[Fri, 16 May 2025 23:30:44 INFO] epoch: 008 - iter: 02400 - train loss: 0.8591 - time elapsed/per batch: 17.0710 0.0854
[Fri, 16 May 2025 23:31:01 INFO] epoch: 008 - iter: 02600 - train loss: 0.8461 - time elapsed/per batch: 17.0170 0.0851
[Fri, 16 May 2025 23:31:18 INFO] epoch: 008 - iter: 02800 - train loss: 0.8510 - time elapsed/per batch: 16.9360 0.0847
[Fri, 16 May 2025 23:31:34 INFO] epoch: 008 - iter: 03000 - train loss: 0.8635 - time elapsed/per batch: 15.9490 0.0797
[Fri, 16 May 2025 23:32:27 INFO] epoch: 008 - iter: 03124 - valid loss: 3.1987 - bleu score: 0.1461 - full evaluation time: 40.9320
[Fri, 16 May 2025 23:32:47 INFO] epoch: 009 - iter: 00200 - train loss: 0.8067 - time elapsed/per batch: 19.5860 0.0979
[Fri, 16 May 2025 23:33:05 INFO] epoch: 009 - iter: 00400 - train loss: 0.8197 - time elapsed/per batch: 18.2170 0.0911
[Fri, 16 May 2025 23:33:23 INFO] epoch: 009 - iter: 00600 - train loss: 0.8397 - time elapsed/per batch: 17.8182 0.0891
[Fri, 16 May 2025 23:33:38 INFO] epoch: 009 - iter: 00800 - train loss: 0.8536 - time elapsed/per batch: 15.2076 0.0760
[Fri, 16 May 2025 23:33:53 INFO] epoch: 009 - iter: 01000 - train loss: 0.8767 - time elapsed/per batch: 15.6187 0.0781
[Fri, 16 May 2025 23:34:10 INFO] epoch: 009 - iter: 01200 - train loss: 0.8476 - time elapsed/per batch: 16.5784 0.0829
[Fri, 16 May 2025 23:34:28 INFO] epoch: 009 - iter: 01400 - train loss: 0.8286 - time elapsed/per batch: 17.8354 0.0892
[Fri, 16 May 2025 23:34:44 INFO] epoch: 009 - iter: 01600 - train loss: 0.8335 - time elapsed/per batch: 16.0995 0.0805
[Fri, 16 May 2025 23:35:01 INFO] epoch: 009 - iter: 01800 - train loss: 0.8507 - time elapsed/per batch: 16.8539 0.0843
[Fri, 16 May 2025 23:35:18 INFO] epoch: 009 - iter: 02000 - train loss: 0.8560 - time elapsed/per batch: 17.5809 0.0879
[Fri, 16 May 2025 23:35:34 INFO] epoch: 009 - iter: 02200 - train loss: 0.8630 - time elapsed/per batch: 15.8188 0.0791
[Fri, 16 May 2025 23:35:50 INFO] epoch: 009 - iter: 02400 - train loss: 0.8279 - time elapsed/per batch: 16.0426 0.0802
[Fri, 16 May 2025 23:36:06 INFO] epoch: 009 - iter: 02600 - train loss: 0.8541 - time elapsed/per batch: 15.6620 0.0783
[Fri, 16 May 2025 23:36:23 INFO] epoch: 009 - iter: 02800 - train loss: 0.8696 - time elapsed/per batch: 16.8615 0.0843
[Fri, 16 May 2025 23:36:40 INFO] epoch: 009 - iter: 03000 - train loss: 0.8579 - time elapsed/per batch: 17.3054 0.0865
[Fri, 16 May 2025 23:37:31 INFO] epoch: 009 - iter: 03124 - valid loss: 3.1470 - bleu score: 0.1567 - full evaluation time: 38.2350
[Fri, 16 May 2025 23:37:48 INFO] epoch: 010 - iter: 00200 - train loss: 0.8156 - time elapsed/per batch: 17.5495 0.0877
[Fri, 16 May 2025 23:38:06 INFO] epoch: 010 - iter: 00400 - train loss: 0.8014 - time elapsed/per batch: 18.2460 0.0912
[Fri, 16 May 2025 23:38:25 INFO] epoch: 010 - iter: 00600 - train loss: 0.8452 - time elapsed/per batch: 18.7765 0.0939
[Fri, 16 May 2025 23:38:42 INFO] epoch: 010 - iter: 00800 - train loss: 0.8055 - time elapsed/per batch: 16.5740 0.0829
[Fri, 16 May 2025 23:38:58 INFO] epoch: 010 - iter: 01000 - train loss: 0.8531 - time elapsed/per batch: 16.1750 0.0809
[Fri, 16 May 2025 23:39:16 INFO] epoch: 010 - iter: 01200 - train loss: 0.8125 - time elapsed/per batch: 18.5610 0.0928
[Fri, 16 May 2025 23:39:33 INFO] epoch: 010 - iter: 01400 - train loss: 0.8306 - time elapsed/per batch: 16.5305 0.0827
[Fri, 16 May 2025 23:39:50 INFO] epoch: 010 - iter: 01600 - train loss: 0.8236 - time elapsed/per batch: 16.6380 0.0832
[Fri, 16 May 2025 23:40:06 INFO] epoch: 010 - iter: 01800 - train loss: 0.8245 - time elapsed/per batch: 15.9790 0.0799
[Fri, 16 May 2025 23:40:24 INFO] epoch: 010 - iter: 02000 - train loss: 0.8198 - time elapsed/per batch: 18.7713 0.0939
[Fri, 16 May 2025 23:40:42 INFO] epoch: 010 - iter: 02200 - train loss: 0.8011 - time elapsed/per batch: 18.1420 0.0907
[Fri, 16 May 2025 23:41:00 INFO] epoch: 010 - iter: 02400 - train loss: 0.8397 - time elapsed/per batch: 17.3740 0.0869
[Fri, 16 May 2025 23:41:17 INFO] epoch: 010 - iter: 02600 - train loss: 0.8389 - time elapsed/per batch: 17.3980 0.0870
[Fri, 16 May 2025 23:41:34 INFO] epoch: 010 - iter: 02800 - train loss: 0.8304 - time elapsed/per batch: 16.7060 0.0835
[Fri, 16 May 2025 23:41:51 INFO] epoch: 010 - iter: 03000 - train loss: 0.8369 - time elapsed/per batch: 16.8195 0.0841
[Fri, 16 May 2025 23:42:42 INFO] epoch: 010 - iter: 03124 - valid loss: 3.1195 - bleu score: 0.1653 - full evaluation time: 39.3955
[Fri, 16 May 2025 23:43:00 INFO] epoch: 011 - iter: 00200 - train loss: 0.8272 - time elapsed/per batch: 17.5090 0.0875
[Fri, 16 May 2025 23:43:17 INFO] epoch: 011 - iter: 00400 - train loss: 0.8263 - time elapsed/per batch: 17.5080 0.0875
[Fri, 16 May 2025 23:43:39 INFO] epoch: 011 - iter: 00600 - train loss: 0.7898 - time elapsed/per batch: 21.3525 0.1068
[Fri, 16 May 2025 23:43:57 INFO] epoch: 011 - iter: 00800 - train loss: 0.8473 - time elapsed/per batch: 18.1691 0.0908
[Fri, 16 May 2025 23:44:12 INFO] epoch: 011 - iter: 01000 - train loss: 0.8290 - time elapsed/per batch: 15.1742 0.0759
[Fri, 16 May 2025 23:44:27 INFO] epoch: 011 - iter: 01200 - train loss: 0.8089 - time elapsed/per batch: 15.1288 0.0756
[Fri, 16 May 2025 23:44:43 INFO] epoch: 011 - iter: 01400 - train loss: 0.8105 - time elapsed/per batch: 15.5857 0.0779
[Fri, 16 May 2025 23:44:58 INFO] epoch: 011 - iter: 01600 - train loss: 0.8429 - time elapsed/per batch: 15.7513 0.0788
[Fri, 16 May 2025 23:45:15 INFO] epoch: 011 - iter: 01800 - train loss: 0.8472 - time elapsed/per batch: 16.9838 0.0849
[Fri, 16 May 2025 23:45:31 INFO] epoch: 011 - iter: 02000 - train loss: 0.8256 - time elapsed/per batch: 15.6635 0.0783
[Fri, 16 May 2025 23:45:47 INFO] epoch: 011 - iter: 02200 - train loss: 0.8743 - time elapsed/per batch: 15.7367 0.0787
[Fri, 16 May 2025 23:46:04 INFO] epoch: 011 - iter: 02400 - train loss: 0.8292 - time elapsed/per batch: 17.0621 0.0853
[Fri, 16 May 2025 23:46:20 INFO] epoch: 011 - iter: 02600 - train loss: 0.8428 - time elapsed/per batch: 16.2825 0.0814
[Fri, 16 May 2025 23:46:38 INFO] epoch: 011 - iter: 02800 - train loss: 0.8257 - time elapsed/per batch: 18.2040 0.0910
[Fri, 16 May 2025 23:46:57 INFO] epoch: 011 - iter: 03000 - train loss: 0.8076 - time elapsed/per batch: 18.6190 0.0931
[Fri, 16 May 2025 23:47:49 INFO] epoch: 011 - iter: 03124 - valid loss: 3.0945 - bleu score: 0.1741 - full evaluation time: 39.2758
[Fri, 16 May 2025 23:48:06 INFO] epoch: 012 - iter: 00200 - train loss: 0.7960 - time elapsed/per batch: 16.6975 0.0835
[Fri, 16 May 2025 23:48:25 INFO] epoch: 012 - iter: 00400 - train loss: 0.7973 - time elapsed/per batch: 19.8770 0.0994
[Fri, 16 May 2025 23:48:44 INFO] epoch: 012 - iter: 00600 - train loss: 0.8151 - time elapsed/per batch: 18.3289 0.0916
[Fri, 16 May 2025 23:49:01 INFO] epoch: 012 - iter: 00800 - train loss: 0.8178 - time elapsed/per batch: 17.2211 0.0861
[Fri, 16 May 2025 23:49:18 INFO] epoch: 012 - iter: 01000 - train loss: 0.8024 - time elapsed/per batch: 16.6842 0.0834
[Fri, 16 May 2025 23:49:33 INFO] epoch: 012 - iter: 01200 - train loss: 0.7937 - time elapsed/per batch: 15.0696 0.0753
[Fri, 16 May 2025 23:49:53 INFO] epoch: 012 - iter: 01400 - train loss: 0.8047 - time elapsed/per batch: 20.5840 0.1029
[Fri, 16 May 2025 23:50:09 INFO] epoch: 012 - iter: 01600 - train loss: 0.8392 - time elapsed/per batch: 15.8024 0.0790
[Fri, 16 May 2025 23:50:26 INFO] epoch: 012 - iter: 01800 - train loss: 0.7821 - time elapsed/per batch: 16.9676 0.0848
[Fri, 16 May 2025 23:50:43 INFO] epoch: 012 - iter: 02000 - train loss: 0.8326 - time elapsed/per batch: 16.8778 0.0844
[Fri, 16 May 2025 23:51:03 INFO] epoch: 012 - iter: 02200 - train loss: 0.8531 - time elapsed/per batch: 19.6961 0.0985
[Fri, 16 May 2025 23:51:41 INFO] epoch: 012 - iter: 02400 - train loss: 0.7882 - time elapsed/per batch: 38.6448 0.1932
[Fri, 16 May 2025 23:52:15 INFO] epoch: 012 - iter: 02600 - train loss: 0.8327 - time elapsed/per batch: 33.5818 0.1679
[Fri, 16 May 2025 23:52:47 INFO] epoch: 012 - iter: 02800 - train loss: 0.7990 - time elapsed/per batch: 32.2748 0.1614
[Fri, 16 May 2025 23:53:22 INFO] epoch: 012 - iter: 03000 - train loss: 0.8053 - time elapsed/per batch: 34.8020 0.1740
[Fri, 16 May 2025 23:54:39 INFO] epoch: 012 - iter: 03124 - valid loss: 3.0546 - bleu score: 0.1848 - full evaluation time: 65.8840
[Fri, 16 May 2025 23:55:14 INFO] epoch: 013 - iter: 00200 - train loss: 0.7918 - time elapsed/per batch: 34.7664 0.1738
[Fri, 16 May 2025 23:55:43 INFO] epoch: 013 - iter: 00400 - train loss: 0.7796 - time elapsed/per batch: 29.9034 0.1495
[Fri, 16 May 2025 23:56:15 INFO] epoch: 013 - iter: 00600 - train loss: 0.7814 - time elapsed/per batch: 31.8719 0.1594
[Fri, 16 May 2025 23:56:36 INFO] epoch: 013 - iter: 00800 - train loss: 0.8021 - time elapsed/per batch: 21.0582 0.1053
[Fri, 16 May 2025 23:57:27 INFO] epoch: 013 - iter: 01000 - train loss: 0.8086 - time elapsed/per batch: 50.9419 0.2547
[Fri, 16 May 2025 23:57:52 INFO] epoch: 013 - iter: 01200 - train loss: 0.8122 - time elapsed/per batch: 24.5320 0.1227
[Fri, 16 May 2025 23:58:26 INFO] epoch: 013 - iter: 01400 - train loss: 0.7979 - time elapsed/per batch: 34.2338 0.1712
[Fri, 16 May 2025 23:59:06 INFO] epoch: 013 - iter: 01600 - train loss: 0.8106 - time elapsed/per batch: 39.9441 0.1997
[Fri, 16 May 2025 23:59:35 INFO] epoch: 013 - iter: 01800 - train loss: 0.7991 - time elapsed/per batch: 29.2364 0.1462
[Sat, 17 May 2025 00:00:03 INFO] epoch: 013 - iter: 02000 - train loss: 0.8004 - time elapsed/per batch: 28.1381 0.1407
[Sat, 17 May 2025 00:00:29 INFO] epoch: 013 - iter: 02200 - train loss: 0.7913 - time elapsed/per batch: 25.2642 0.1263
[Sat, 17 May 2025 00:01:20 INFO] epoch: 013 - iter: 02400 - train loss: 0.7867 - time elapsed/per batch: 51.4479 0.2572
[Sat, 17 May 2025 00:01:58 INFO] epoch: 013 - iter: 02600 - train loss: 0.8315 - time elapsed/per batch: 38.2199 0.1911
[Sat, 17 May 2025 00:02:26 INFO] epoch: 013 - iter: 02800 - train loss: 0.8059 - time elapsed/per batch: 27.9686 0.1398
[Sat, 17 May 2025 00:02:50 INFO] epoch: 013 - iter: 03000 - train loss: 0.8026 - time elapsed/per batch: 23.9923 0.1200
[Sat, 17 May 2025 00:03:54 INFO] epoch: 013 - iter: 03124 - valid loss: 3.0396 - bleu score: 0.1857 - full evaluation time: 49.8707
[Sat, 17 May 2025 00:04:19 INFO] epoch: 014 - iter: 00200 - train loss: 0.7764 - time elapsed/per batch: 25.5275 0.1276
[Sat, 17 May 2025 00:04:49 INFO] epoch: 014 - iter: 00400 - train loss: 0.7932 - time elapsed/per batch: 29.3015 0.1465
[Sat, 17 May 2025 00:05:16 INFO] epoch: 014 - iter: 00600 - train loss: 0.7720 - time elapsed/per batch: 27.3764 0.1369
[Sat, 17 May 2025 00:05:34 INFO] epoch: 014 - iter: 00800 - train loss: 0.7824 - time elapsed/per batch: 18.4928 0.0925
[Sat, 17 May 2025 00:06:02 INFO] epoch: 014 - iter: 01000 - train loss: 0.8015 - time elapsed/per batch: 27.2383 0.1362
[Sat, 17 May 2025 00:06:43 INFO] epoch: 014 - iter: 01200 - train loss: 0.7605 - time elapsed/per batch: 41.8511 0.2093
[Sat, 17 May 2025 00:07:15 INFO] epoch: 014 - iter: 01400 - train loss: 0.7887 - time elapsed/per batch: 31.1298 0.1556
[Sat, 17 May 2025 00:07:51 INFO] epoch: 014 - iter: 01600 - train loss: 0.7864 - time elapsed/per batch: 36.1485 0.1807
[Sat, 17 May 2025 00:08:17 INFO] epoch: 014 - iter: 01800 - train loss: 0.7832 - time elapsed/per batch: 26.1895 0.1309
[Sat, 17 May 2025 00:09:13 INFO] epoch: 014 - iter: 02000 - train loss: 0.7869 - time elapsed/per batch: 55.9142 0.2796
[Sat, 17 May 2025 00:09:40 INFO] epoch: 014 - iter: 02200 - train loss: 0.7771 - time elapsed/per batch: 26.7482 0.1337
[Sat, 17 May 2025 00:10:20 INFO] epoch: 014 - iter: 02400 - train loss: 0.7744 - time elapsed/per batch: 40.2810 0.2014
[Sat, 17 May 2025 00:10:46 INFO] epoch: 014 - iter: 02600 - train loss: 0.8132 - time elapsed/per batch: 25.6386 0.1282
[Sat, 17 May 2025 00:11:26 INFO] epoch: 014 - iter: 02800 - train loss: 0.8392 - time elapsed/per batch: 40.9301 0.2047
[Sat, 17 May 2025 00:12:13 INFO] epoch: 014 - iter: 03000 - train loss: 0.8154 - time elapsed/per batch: 46.6975 0.2335
[Sat, 17 May 2025 00:13:29 INFO] epoch: 014 - iter: 03124 - valid loss: 3.0203 - bleu score: 0.1949 - full evaluation time: 61.8393
[Sat, 17 May 2025 00:13:59 INFO] epoch: 015 - iter: 00200 - train loss: 0.7694 - time elapsed/per batch: 29.8662 0.1493
[Sat, 17 May 2025 00:14:21 INFO] epoch: 015 - iter: 00400 - train loss: 0.7845 - time elapsed/per batch: 21.6461 0.1082
[Sat, 17 May 2025 00:14:47 INFO] epoch: 015 - iter: 00600 - train loss: 0.7715 - time elapsed/per batch: 26.5000 0.1325
[Sat, 17 May 2025 00:15:13 INFO] epoch: 015 - iter: 00800 - train loss: 0.7651 - time elapsed/per batch: 26.1022 0.1305
[Sat, 17 May 2025 00:15:46 INFO] epoch: 015 - iter: 01000 - train loss: 0.7659 - time elapsed/per batch: 32.5575 0.1628
[Sat, 17 May 2025 00:16:08 INFO] epoch: 015 - iter: 01200 - train loss: 0.7761 - time elapsed/per batch: 21.6608 0.1083
[Sat, 17 May 2025 00:16:45 INFO] epoch: 015 - iter: 01400 - train loss: 0.7893 - time elapsed/per batch: 37.2445 0.1862
[Sat, 17 May 2025 00:17:16 INFO] epoch: 015 - iter: 01600 - train loss: 0.7725 - time elapsed/per batch: 31.6979 0.1585
[Sat, 17 May 2025 00:17:54 INFO] epoch: 015 - iter: 01800 - train loss: 0.7982 - time elapsed/per batch: 37.7359 0.1887
[Sat, 17 May 2025 00:18:25 INFO] epoch: 015 - iter: 02000 - train loss: 0.7642 - time elapsed/per batch: 30.6162 0.1531
[Sat, 17 May 2025 00:19:08 INFO] epoch: 015 - iter: 02200 - train loss: 0.7715 - time elapsed/per batch: 43.5222 0.2176
[Sat, 17 May 2025 00:19:47 INFO] epoch: 015 - iter: 02400 - train loss: 0.8151 - time elapsed/per batch: 38.8388 0.1942
[Sat, 17 May 2025 00:20:12 INFO] epoch: 015 - iter: 02600 - train loss: 0.7701 - time elapsed/per batch: 25.2363 0.1262
[Sat, 17 May 2025 00:20:39 INFO] epoch: 015 - iter: 02800 - train loss: 0.8151 - time elapsed/per batch: 26.7687 0.1338
[Sat, 17 May 2025 00:21:25 INFO] epoch: 015 - iter: 03000 - train loss: 0.7980 - time elapsed/per batch: 45.4293 0.2271
[Sat, 17 May 2025 00:23:18 INFO] epoch: 015 - iter: 03124 - valid loss: 2.9998 - bleu score: 0.2022 - full evaluation time: 71.6927
[Sat, 17 May 2025 00:23:50 INFO] epoch: 016 - iter: 00200 - train loss: 0.7729 - time elapsed/per batch: 32.2752 0.1614
[Sat, 17 May 2025 00:24:57 INFO] epoch: 016 - iter: 00400 - train loss: 0.7703 - time elapsed/per batch: 67.4912 0.3375
[Sat, 17 May 2025 00:25:37 INFO] epoch: 016 - iter: 00600 - train loss: 0.7771 - time elapsed/per batch: 39.8117 0.1991
[Sat, 17 May 2025 00:26:10 INFO] epoch: 016 - iter: 00800 - train loss: 0.7639 - time elapsed/per batch: 32.5712 0.1629
[Sat, 17 May 2025 00:26:31 INFO] epoch: 016 - iter: 01000 - train loss: 0.7819 - time elapsed/per batch: 21.0383 0.1052
[Sat, 17 May 2025 00:27:13 INFO] epoch: 016 - iter: 01200 - train loss: 0.7875 - time elapsed/per batch: 42.3235 0.2116
[Sat, 17 May 2025 00:27:43 INFO] epoch: 016 - iter: 01400 - train loss: 0.7581 - time elapsed/per batch: 29.7278 0.1486
[Sat, 17 May 2025 00:28:26 INFO] epoch: 016 - iter: 01600 - train loss: 0.7807 - time elapsed/per batch: 43.3679 0.2168
[Sat, 17 May 2025 00:28:55 INFO] epoch: 016 - iter: 01800 - train loss: 0.7656 - time elapsed/per batch: 28.5798 0.1429
[Sat, 17 May 2025 00:29:23 INFO] epoch: 016 - iter: 02000 - train loss: 0.7762 - time elapsed/per batch: 28.3328 0.1417
[Sat, 17 May 2025 00:29:58 INFO] epoch: 016 - iter: 02200 - train loss: 0.7821 - time elapsed/per batch: 34.7388 0.1737
[Sat, 17 May 2025 00:30:18 INFO] epoch: 016 - iter: 02400 - train loss: 0.7766 - time elapsed/per batch: 19.6428 0.0982
[Sat, 17 May 2025 00:30:35 INFO] epoch: 016 - iter: 02600 - train loss: 0.7887 - time elapsed/per batch: 17.4460 0.0872
[Sat, 17 May 2025 00:31:00 INFO] epoch: 016 - iter: 02800 - train loss: 0.7721 - time elapsed/per batch: 25.4147 0.1271
[Sat, 17 May 2025 00:31:18 INFO] epoch: 016 - iter: 03000 - train loss: 0.8022 - time elapsed/per batch: 17.7284 0.0886
[Sat, 17 May 2025 00:32:08 INFO] epoch: 016 - iter: 03124 - valid loss: 2.9753 - bleu score: 0.2020 - full evaluation time: 39.4082
[Sat, 17 May 2025 00:32:40 INFO] epoch: 017 - iter: 00200 - train loss: 0.7737 - time elapsed/per batch: 31.8572 0.1593
[Sat, 17 May 2025 00:33:02 INFO] epoch: 017 - iter: 00400 - train loss: 0.7654 - time elapsed/per batch: 21.2968 0.1065
[Sat, 17 May 2025 00:33:30 INFO] epoch: 017 - iter: 00600 - train loss: 0.7665 - time elapsed/per batch: 28.1455 0.1407
[Sat, 17 May 2025 00:33:47 INFO] epoch: 017 - iter: 00800 - train loss: 0.7784 - time elapsed/per batch: 16.8017 0.0840
[Sat, 17 May 2025 00:34:04 INFO] epoch: 017 - iter: 01000 - train loss: 0.7725 - time elapsed/per batch: 17.4552 0.0873
[Sat, 17 May 2025 00:34:24 INFO] epoch: 017 - iter: 01200 - train loss: 0.7676 - time elapsed/per batch: 20.3321 0.1017
[Sat, 17 May 2025 00:34:39 INFO] epoch: 017 - iter: 01400 - train loss: 0.7709 - time elapsed/per batch: 14.7260 0.0736
[Sat, 17 May 2025 00:34:56 INFO] epoch: 017 - iter: 01600 - train loss: 0.7549 - time elapsed/per batch: 17.1690 0.0858
[Sat, 17 May 2025 00:35:15 INFO] epoch: 017 - iter: 01800 - train loss: 0.7493 - time elapsed/per batch: 18.8445 0.0942
[Sat, 17 May 2025 00:35:34 INFO] epoch: 017 - iter: 02000 - train loss: 0.7592 - time elapsed/per batch: 18.7505 0.0938
[Sat, 17 May 2025 00:35:50 INFO] epoch: 017 - iter: 02200 - train loss: 0.7495 - time elapsed/per batch: 15.7040 0.0785
[Sat, 17 May 2025 00:36:05 INFO] epoch: 017 - iter: 02400 - train loss: 0.7648 - time elapsed/per batch: 15.8915 0.0795
[Sat, 17 May 2025 00:36:23 INFO] epoch: 017 - iter: 02600 - train loss: 0.7420 - time elapsed/per batch: 17.6860 0.0884
[Sat, 17 May 2025 00:36:44 INFO] epoch: 017 - iter: 02800 - train loss: 0.7794 - time elapsed/per batch: 20.9220 0.1046
[Sat, 17 May 2025 00:37:02 INFO] epoch: 017 - iter: 03000 - train loss: 0.7688 - time elapsed/per batch: 18.1369 0.0907
[Sat, 17 May 2025 00:38:07 INFO] epoch: 017 - iter: 03124 - valid loss: 2.9590 - bleu score: 0.2086 - full evaluation time: 55.2310
[Sat, 17 May 2025 00:38:34 INFO] epoch: 018 - iter: 00200 - train loss: 0.7501 - time elapsed/per batch: 27.2427 0.1362
[Sat, 17 May 2025 00:39:05 INFO] epoch: 018 - iter: 00400 - train loss: 0.7428 - time elapsed/per batch: 30.9547 0.1548
[Sat, 17 May 2025 00:39:30 INFO] epoch: 018 - iter: 00600 - train loss: 0.7654 - time elapsed/per batch: 24.2332 0.1212
[Sat, 17 May 2025 00:40:05 INFO] epoch: 018 - iter: 00800 - train loss: 0.7536 - time elapsed/per batch: 34.9319 0.1747
[Sat, 17 May 2025 00:40:35 INFO] epoch: 018 - iter: 01000 - train loss: 0.7701 - time elapsed/per batch: 30.0619 0.1503
[Sat, 17 May 2025 00:40:54 INFO] epoch: 018 - iter: 01200 - train loss: 0.7437 - time elapsed/per batch: 19.7775 0.0989
[Sat, 17 May 2025 00:41:27 INFO] epoch: 018 - iter: 01400 - train loss: 0.7750 - time elapsed/per batch: 32.5532 0.1628
[Sat, 17 May 2025 00:42:03 INFO] epoch: 018 - iter: 01600 - train loss: 0.7619 - time elapsed/per batch: 36.5004 0.1825
[Sat, 17 May 2025 00:42:39 INFO] epoch: 018 - iter: 01800 - train loss: 0.7831 - time elapsed/per batch: 35.5222 0.1776
[Sat, 17 May 2025 00:43:13 INFO] epoch: 018 - iter: 02000 - train loss: 0.7819 - time elapsed/per batch: 34.1859 0.1709
[Sat, 17 May 2025 00:43:45 INFO] epoch: 018 - iter: 02200 - train loss: 0.7698 - time elapsed/per batch: 32.1210 0.1606
[Sat, 17 May 2025 00:44:00 INFO] epoch: 018 - iter: 02400 - train loss: 0.7660 - time elapsed/per batch: 14.6605 0.0733
[Sat, 17 May 2025 00:44:20 INFO] epoch: 018 - iter: 02600 - train loss: 0.7562 - time elapsed/per batch: 19.6858 0.0984
[Sat, 17 May 2025 00:44:37 INFO] epoch: 018 - iter: 02800 - train loss: 0.7577 - time elapsed/per batch: 17.4442 0.0872
[Sat, 17 May 2025 00:44:55 INFO] epoch: 018 - iter: 03000 - train loss: 0.7470 - time elapsed/per batch: 18.2642 0.0913
[Sat, 17 May 2025 00:45:59 INFO] epoch: 018 - iter: 03124 - valid loss: 2.9500 - bleu score: 0.2107 - full evaluation time: 40.4660
[Sat, 17 May 2025 00:46:27 INFO] epoch: 019 - iter: 00200 - train loss: 0.7390 - time elapsed/per batch: 27.4000 0.1370
[Sat, 17 May 2025 00:47:07 INFO] epoch: 019 - iter: 00400 - train loss: 0.7266 - time elapsed/per batch: 40.1627 0.2008
