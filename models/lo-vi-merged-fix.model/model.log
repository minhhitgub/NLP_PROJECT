[Sat, 17 May 2025 06:41:40 INFO] .lo * src vocab size = 12872
[Sat, 17 May 2025 06:41:40 INFO] .vi * tgt vocab size = 9167
[Sat, 17 May 2025 06:41:40 INFO] Building model...
[Sat, 17 May 2025 06:41:40 INFO] Transformer(
  (encoder): Encoder(
    (embed): Embedding(12872, 256)
    (pe): PositionalEncoder(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (layers): ModuleList(
      (0): EncoderLayer(
        (norm_1): Norm()
        (norm_2): Norm()
        (attn): MultiHeadAttention(
          (q_linear): Linear(in_features=256, out_features=256, bias=True)
          (k_linear): Linear(in_features=256, out_features=256, bias=True)
          (v_linear): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (out): Linear(in_features=256, out_features=256, bias=True)
        )
        (ff): FeedForward(
          (linear_1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (dropout_1): Dropout(p=0.1, inplace=False)
        (dropout_2): Dropout(p=0.1, inplace=False)
      )
      (1): EncoderLayer(
        (norm_1): Norm()
        (norm_2): Norm()
        (attn): MultiHeadAttention(
          (q_linear): Linear(in_features=256, out_features=256, bias=True)
          (k_linear): Linear(in_features=256, out_features=256, bias=True)
          (v_linear): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (out): Linear(in_features=256, out_features=256, bias=True)
        )
        (ff): FeedForward(
          (linear_1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (dropout_1): Dropout(p=0.1, inplace=False)
        (dropout_2): Dropout(p=0.1, inplace=False)
      )
      (2): EncoderLayer(
        (norm_1): Norm()
        (norm_2): Norm()
        (attn): MultiHeadAttention(
          (q_linear): Linear(in_features=256, out_features=256, bias=True)
          (k_linear): Linear(in_features=256, out_features=256, bias=True)
          (v_linear): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (out): Linear(in_features=256, out_features=256, bias=True)
        )
        (ff): FeedForward(
          (linear_1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (dropout_1): Dropout(p=0.1, inplace=False)
        (dropout_2): Dropout(p=0.1, inplace=False)
      )
      (3): EncoderLayer(
        (norm_1): Norm()
        (norm_2): Norm()
        (attn): MultiHeadAttention(
          (q_linear): Linear(in_features=256, out_features=256, bias=True)
          (k_linear): Linear(in_features=256, out_features=256, bias=True)
          (v_linear): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (out): Linear(in_features=256, out_features=256, bias=True)
        )
        (ff): FeedForward(
          (linear_1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (dropout_1): Dropout(p=0.1, inplace=False)
        (dropout_2): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): Norm()
  )
  (decoder): Decoder(
    (embed): Embedding(9167, 256)
    (pe): PositionalEncoder(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (layers): ModuleList(
      (0): DecoderLayer(
        (norm_1): Norm()
        (norm_2): Norm()
        (norm_3): Norm()
        (dropout_1): Dropout(p=0.1, inplace=False)
        (dropout_2): Dropout(p=0.1, inplace=False)
        (dropout_3): Dropout(p=0.1, inplace=False)
        (attn_1): MultiHeadAttention(
          (q_linear): Linear(in_features=256, out_features=256, bias=True)
          (k_linear): Linear(in_features=256, out_features=256, bias=True)
          (v_linear): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (out): Linear(in_features=256, out_features=256, bias=True)
        )
        (attn_2): MultiHeadAttention(
          (q_linear): Linear(in_features=256, out_features=256, bias=True)
          (k_linear): Linear(in_features=256, out_features=256, bias=True)
          (v_linear): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (out): Linear(in_features=256, out_features=256, bias=True)
        )
        (ff): FeedForward(
          (linear_1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_2): Linear(in_features=2048, out_features=256, bias=True)
        )
      )
      (1): DecoderLayer(
        (norm_1): Norm()
        (norm_2): Norm()
        (norm_3): Norm()
        (dropout_1): Dropout(p=0.1, inplace=False)
        (dropout_2): Dropout(p=0.1, inplace=False)
        (dropout_3): Dropout(p=0.1, inplace=False)
        (attn_1): MultiHeadAttention(
          (q_linear): Linear(in_features=256, out_features=256, bias=True)
          (k_linear): Linear(in_features=256, out_features=256, bias=True)
          (v_linear): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (out): Linear(in_features=256, out_features=256, bias=True)
        )
        (attn_2): MultiHeadAttention(
          (q_linear): Linear(in_features=256, out_features=256, bias=True)
          (k_linear): Linear(in_features=256, out_features=256, bias=True)
          (v_linear): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (out): Linear(in_features=256, out_features=256, bias=True)
        )
        (ff): FeedForward(
          (linear_1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_2): Linear(in_features=2048, out_features=256, bias=True)
        )
      )
      (2): DecoderLayer(
        (norm_1): Norm()
        (norm_2): Norm()
        (norm_3): Norm()
        (dropout_1): Dropout(p=0.1, inplace=False)
        (dropout_2): Dropout(p=0.1, inplace=False)
        (dropout_3): Dropout(p=0.1, inplace=False)
        (attn_1): MultiHeadAttention(
          (q_linear): Linear(in_features=256, out_features=256, bias=True)
          (k_linear): Linear(in_features=256, out_features=256, bias=True)
          (v_linear): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (out): Linear(in_features=256, out_features=256, bias=True)
        )
        (attn_2): MultiHeadAttention(
          (q_linear): Linear(in_features=256, out_features=256, bias=True)
          (k_linear): Linear(in_features=256, out_features=256, bias=True)
          (v_linear): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (out): Linear(in_features=256, out_features=256, bias=True)
        )
        (ff): FeedForward(
          (linear_1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_2): Linear(in_features=2048, out_features=256, bias=True)
        )
      )
      (3): DecoderLayer(
        (norm_1): Norm()
        (norm_2): Norm()
        (norm_3): Norm()
        (dropout_1): Dropout(p=0.1, inplace=False)
        (dropout_2): Dropout(p=0.1, inplace=False)
        (dropout_3): Dropout(p=0.1, inplace=False)
        (attn_1): MultiHeadAttention(
          (q_linear): Linear(in_features=256, out_features=256, bias=True)
          (k_linear): Linear(in_features=256, out_features=256, bias=True)
          (v_linear): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (out): Linear(in_features=256, out_features=256, bias=True)
        )
        (attn_2): MultiHeadAttention(
          (q_linear): Linear(in_features=256, out_features=256, bias=True)
          (k_linear): Linear(in_features=256, out_features=256, bias=True)
          (v_linear): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (out): Linear(in_features=256, out_features=256, bias=True)
        )
        (ff): FeedForward(
          (linear_1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_2): Linear(in_features=2048, out_features=256, bias=True)
        )
      )
    )
    (norm): Norm()
  )
  (out): Linear(in_features=256, out_features=9167, bias=True)
)
[Sat, 17 May 2025 06:41:40 INFO] Encoder: 8556032
[Sat, 17 May 2025 06:41:40 INFO] Decoder: 8662272
[Sat, 17 May 2025 06:41:40 INFO] * Number of parameters: 17218304
[Sat, 17 May 2025 06:41:40 INFO] Starting training on cuda
[Sat, 17 May 2025 06:41:53 INFO] epoch: 001 - iter: 00200 - train loss: 1.1363 - time elapsed/per batch: 13.4681 0.0673
[Sat, 17 May 2025 06:42:05 INFO] epoch: 001 - iter: 00400 - train loss: 1.1811 - time elapsed/per batch: 11.8669 0.0593
[Sat, 17 May 2025 06:42:17 INFO] epoch: 001 - iter: 00600 - train loss: 1.1749 - time elapsed/per batch: 12.1101 0.0606
[Sat, 17 May 2025 06:42:30 INFO] epoch: 001 - iter: 00800 - train loss: 1.1461 - time elapsed/per batch: 12.4593 0.0623
[Sat, 17 May 2025 06:42:42 INFO] epoch: 001 - iter: 01000 - train loss: 1.1875 - time elapsed/per batch: 12.1850 0.0609
[Sat, 17 May 2025 06:42:54 INFO] epoch: 001 - iter: 01200 - train loss: 1.1671 - time elapsed/per batch: 12.1390 0.0607
[Sat, 17 May 2025 06:43:06 INFO] epoch: 001 - iter: 01400 - train loss: 1.1783 - time elapsed/per batch: 11.9467 0.0597
[Sat, 17 May 2025 06:43:18 INFO] epoch: 001 - iter: 01600 - train loss: 1.1324 - time elapsed/per batch: 12.3571 0.0618
[Sat, 17 May 2025 06:43:30 INFO] epoch: 001 - iter: 01800 - train loss: 1.1599 - time elapsed/per batch: 12.0880 0.0604
[Sat, 17 May 2025 06:43:44 INFO] epoch: 001 - iter: 02000 - train loss: 1.1337 - time elapsed/per batch: 14.1765 0.0709
[Sat, 17 May 2025 06:44:00 INFO] epoch: 001 - iter: 02200 - train loss: 1.1157 - time elapsed/per batch: 15.0300 0.0752
[Sat, 17 May 2025 06:44:12 INFO] epoch: 001 - iter: 02400 - train loss: 1.1559 - time elapsed/per batch: 12.6585 0.0633
[Sat, 17 May 2025 06:44:27 INFO] epoch: 001 - iter: 02600 - train loss: 1.1160 - time elapsed/per batch: 15.0275 0.0751
[Sat, 17 May 2025 06:44:41 INFO] epoch: 001 - iter: 02800 - train loss: 1.1280 - time elapsed/per batch: 14.2020 0.0710
[Sat, 17 May 2025 06:44:58 INFO] epoch: 001 - iter: 03000 - train loss: 1.1083 - time elapsed/per batch: 16.2897 0.0814
[Sat, 17 May 2025 06:45:11 INFO] epoch: 001 - iter: 03200 - train loss: 1.1204 - time elapsed/per batch: 12.9003 0.0645
[Sat, 17 May 2025 06:45:23 INFO] epoch: 001 - iter: 03400 - train loss: 1.1399 - time elapsed/per batch: 12.2669 0.0613
[Sat, 17 May 2025 06:45:35 INFO] epoch: 001 - iter: 03600 - train loss: 1.1192 - time elapsed/per batch: 12.2395 0.0612
[Sat, 17 May 2025 06:45:47 INFO] epoch: 001 - iter: 03800 - train loss: 1.1582 - time elapsed/per batch: 11.9940 0.0600
[Sat, 17 May 2025 06:46:00 INFO] epoch: 001 - iter: 04000 - train loss: 1.1399 - time elapsed/per batch: 12.9451 0.0647
[Sat, 17 May 2025 06:46:13 INFO] epoch: 001 - iter: 04200 - train loss: 1.1236 - time elapsed/per batch: 12.6591 0.0633
[Sat, 17 May 2025 06:46:27 INFO] epoch: 001 - iter: 04400 - train loss: 1.1018 - time elapsed/per batch: 13.8843 0.0694
[Sat, 17 May 2025 06:46:39 INFO] epoch: 001 - iter: 04600 - train loss: 1.1089 - time elapsed/per batch: 12.5268 0.0626
[Sat, 17 May 2025 06:46:52 INFO] epoch: 001 - iter: 04800 - train loss: 1.0612 - time elapsed/per batch: 13.1926 0.0660
[Sat, 17 May 2025 06:47:05 INFO] epoch: 001 - iter: 05000 - train loss: 1.0933 - time elapsed/per batch: 12.6020 0.0630
[Sat, 17 May 2025 06:47:17 INFO] epoch: 001 - iter: 05200 - train loss: 1.0985 - time elapsed/per batch: 12.3675 0.0618
[Sat, 17 May 2025 06:47:30 INFO] epoch: 001 - iter: 05400 - train loss: 1.0646 - time elapsed/per batch: 12.6671 0.0633
[Sat, 17 May 2025 06:47:46 INFO] epoch: 001 - iter: 05600 - train loss: 1.0749 - time elapsed/per batch: 15.6360 0.0782
[Sat, 17 May 2025 06:48:25 INFO] epoch: 001 - iter: 05745 - valid loss: 4.2124 - bleu score: 0.0289 - full evaluation time: 30.1726
[Sat, 17 May 2025 06:48:42 INFO] epoch: 002 - iter: 00200 - train loss: 1.0890 - time elapsed/per batch: 17.2625 0.0863
[Sat, 17 May 2025 06:48:55 INFO] epoch: 002 - iter: 00400 - train loss: 1.0338 - time elapsed/per batch: 13.1744 0.0659
[Sat, 17 May 2025 06:49:08 INFO] epoch: 002 - iter: 00600 - train loss: 1.0734 - time elapsed/per batch: 12.2284 0.0611
[Sat, 17 May 2025 06:49:21 INFO] epoch: 002 - iter: 00800 - train loss: 1.0385 - time elapsed/per batch: 13.9030 0.0695
[Sat, 17 May 2025 06:49:34 INFO] epoch: 002 - iter: 01000 - train loss: 1.0699 - time elapsed/per batch: 12.3522 0.0618
[Sat, 17 May 2025 06:49:46 INFO] epoch: 002 - iter: 01200 - train loss: 1.0532 - time elapsed/per batch: 12.3834 0.0619
[Sat, 17 May 2025 06:49:59 INFO] epoch: 002 - iter: 01400 - train loss: 1.0462 - time elapsed/per batch: 12.3685 0.0618
[Sat, 17 May 2025 06:50:11 INFO] epoch: 002 - iter: 01600 - train loss: 1.0450 - time elapsed/per batch: 12.6438 0.0632
[Sat, 17 May 2025 06:50:25 INFO] epoch: 002 - iter: 01800 - train loss: 1.0047 - time elapsed/per batch: 13.3370 0.0667
[Sat, 17 May 2025 06:50:37 INFO] epoch: 002 - iter: 02000 - train loss: 1.0712 - time elapsed/per batch: 12.2952 0.0615
[Sat, 17 May 2025 06:50:50 INFO] epoch: 002 - iter: 02200 - train loss: 0.9988 - time elapsed/per batch: 13.0721 0.0654
[Sat, 17 May 2025 06:51:02 INFO] epoch: 002 - iter: 02400 - train loss: 1.0443 - time elapsed/per batch: 12.3471 0.0617
[Sat, 17 May 2025 06:51:15 INFO] epoch: 002 - iter: 02600 - train loss: 1.0251 - time elapsed/per batch: 12.7150 0.0636
[Sat, 17 May 2025 06:51:29 INFO] epoch: 002 - iter: 02800 - train loss: 1.0609 - time elapsed/per batch: 13.8343 0.0692
[Sat, 17 May 2025 06:51:42 INFO] epoch: 002 - iter: 03000 - train loss: 1.0075 - time elapsed/per batch: 12.8300 0.0642
[Sat, 17 May 2025 06:51:55 INFO] epoch: 002 - iter: 03200 - train loss: 1.0375 - time elapsed/per batch: 13.4920 0.0675
[Sat, 17 May 2025 06:52:09 INFO] epoch: 002 - iter: 03400 - train loss: 0.9898 - time elapsed/per batch: 13.7990 0.0690
[Sat, 17 May 2025 06:52:21 INFO] epoch: 002 - iter: 03600 - train loss: 1.0484 - time elapsed/per batch: 12.1405 0.0607
[Sat, 17 May 2025 06:52:34 INFO] epoch: 002 - iter: 03800 - train loss: 1.0158 - time elapsed/per batch: 12.8071 0.0640
[Sat, 17 May 2025 06:52:48 INFO] epoch: 002 - iter: 04000 - train loss: 0.9871 - time elapsed/per batch: 13.8492 0.0692
[Sat, 17 May 2025 06:53:00 INFO] epoch: 002 - iter: 04200 - train loss: 1.0206 - time elapsed/per batch: 12.4821 0.0624
[Sat, 17 May 2025 06:53:14 INFO] epoch: 002 - iter: 04400 - train loss: 0.9803 - time elapsed/per batch: 13.4780 0.0674
[Sat, 17 May 2025 06:53:26 INFO] epoch: 002 - iter: 04600 - train loss: 0.9879 - time elapsed/per batch: 12.6973 0.0635
[Sat, 17 May 2025 06:53:39 INFO] epoch: 002 - iter: 04800 - train loss: 0.9982 - time elapsed/per batch: 12.7400 0.0637
[Sat, 17 May 2025 06:53:52 INFO] epoch: 002 - iter: 05000 - train loss: 0.9885 - time elapsed/per batch: 12.5356 0.0627
[Sat, 17 May 2025 06:54:04 INFO] epoch: 002 - iter: 05200 - train loss: 0.9857 - time elapsed/per batch: 12.8011 0.0640
[Sat, 17 May 2025 06:54:17 INFO] epoch: 002 - iter: 05400 - train loss: 1.0078 - time elapsed/per batch: 12.2470 0.0612
[Sat, 17 May 2025 06:54:29 INFO] epoch: 002 - iter: 05600 - train loss: 0.9881 - time elapsed/per batch: 12.6010 0.0630
[Sat, 17 May 2025 06:55:13 INFO] epoch: 002 - iter: 05745 - valid loss: 3.9694 - bleu score: 0.0488 - full evaluation time: 30.5451
[Sat, 17 May 2025 06:55:27 INFO] epoch: 003 - iter: 00200 - train loss: 0.9599 - time elapsed/per batch: 14.2240 0.0711
[Sat, 17 May 2025 06:55:40 INFO] epoch: 003 - iter: 00400 - train loss: 0.9787 - time elapsed/per batch: 12.5773 0.0629
[Sat, 17 May 2025 06:55:52 INFO] epoch: 003 - iter: 00600 - train loss: 0.9543 - time elapsed/per batch: 12.7214 0.0636
[Sat, 17 May 2025 06:56:05 INFO] epoch: 003 - iter: 00800 - train loss: 0.9689 - time elapsed/per batch: 12.4585 0.0623
[Sat, 17 May 2025 06:56:18 INFO] epoch: 003 - iter: 01000 - train loss: 0.9413 - time elapsed/per batch: 12.7339 0.0637
[Sat, 17 May 2025 06:56:31 INFO] epoch: 003 - iter: 01200 - train loss: 0.9708 - time elapsed/per batch: 13.5970 0.0680
[Sat, 17 May 2025 06:56:43 INFO] epoch: 003 - iter: 01400 - train loss: 0.9888 - time elapsed/per batch: 12.2269 0.0611
[Sat, 17 May 2025 06:56:56 INFO] epoch: 003 - iter: 01600 - train loss: 0.9708 - time elapsed/per batch: 12.7010 0.0635
[Sat, 17 May 2025 06:57:09 INFO] epoch: 003 - iter: 01800 - train loss: 0.9783 - time elapsed/per batch: 12.3762 0.0619
[Sat, 17 May 2025 06:57:21 INFO] epoch: 003 - iter: 02000 - train loss: 0.9780 - time elapsed/per batch: 12.6691 0.0633
[Sat, 17 May 2025 06:57:34 INFO] epoch: 003 - iter: 02200 - train loss: 0.9679 - time elapsed/per batch: 12.3570 0.0618
[Sat, 17 May 2025 06:57:46 INFO] epoch: 003 - iter: 02400 - train loss: 0.9622 - time elapsed/per batch: 12.5370 0.0627
[Sat, 17 May 2025 06:57:58 INFO] epoch: 003 - iter: 02600 - train loss: 0.9604 - time elapsed/per batch: 12.2660 0.0613
[Sat, 17 May 2025 06:58:11 INFO] epoch: 003 - iter: 02800 - train loss: 0.9434 - time elapsed/per batch: 12.4958 0.0625
[Sat, 17 May 2025 06:58:23 INFO] epoch: 003 - iter: 03000 - train loss: 0.9745 - time elapsed/per batch: 12.4820 0.0624
[Sat, 17 May 2025 06:58:37 INFO] epoch: 003 - iter: 03200 - train loss: 0.9617 - time elapsed/per batch: 13.5602 0.0678
[Sat, 17 May 2025 06:58:50 INFO] epoch: 003 - iter: 03400 - train loss: 0.9462 - time elapsed/per batch: 12.7408 0.0637
[Sat, 17 May 2025 06:59:03 INFO] epoch: 003 - iter: 03600 - train loss: 0.9353 - time elapsed/per batch: 13.6620 0.0683
[Sat, 17 May 2025 06:59:16 INFO] epoch: 003 - iter: 03800 - train loss: 0.9587 - time elapsed/per batch: 12.2560 0.0613
[Sat, 17 May 2025 06:59:32 INFO] epoch: 003 - iter: 04000 - train loss: 0.9537 - time elapsed/per batch: 16.6819 0.0834
[Sat, 17 May 2025 06:59:47 INFO] epoch: 003 - iter: 04200 - train loss: 0.9352 - time elapsed/per batch: 14.7961 0.0740
[Sat, 17 May 2025 07:00:00 INFO] epoch: 003 - iter: 04400 - train loss: 0.9505 - time elapsed/per batch: 12.7903 0.0640
[Sat, 17 May 2025 07:00:12 INFO] epoch: 003 - iter: 04600 - train loss: 0.9365 - time elapsed/per batch: 12.5105 0.0626
[Sat, 17 May 2025 07:00:27 INFO] epoch: 003 - iter: 04800 - train loss: 0.9316 - time elapsed/per batch: 14.5640 0.0728
[Sat, 17 May 2025 07:00:40 INFO] epoch: 003 - iter: 05000 - train loss: 0.9362 - time elapsed/per batch: 13.2940 0.0665
[Sat, 17 May 2025 07:00:53 INFO] epoch: 003 - iter: 05200 - train loss: 0.9553 - time elapsed/per batch: 12.5275 0.0626
[Sat, 17 May 2025 07:01:05 INFO] epoch: 003 - iter: 05400 - train loss: 0.9177 - time elapsed/per batch: 12.7400 0.0637
[Sat, 17 May 2025 07:01:20 INFO] epoch: 003 - iter: 05600 - train loss: 0.9345 - time elapsed/per batch: 14.5241 0.0726
[Sat, 17 May 2025 07:02:02 INFO] epoch: 003 - iter: 05745 - valid loss: 3.8259 - bleu score: 0.0643 - full evaluation time: 30.8015
[Sat, 17 May 2025 07:02:16 INFO] epoch: 004 - iter: 00200 - train loss: 0.9229 - time elapsed/per batch: 13.6890 0.0684
[Sat, 17 May 2025 07:02:32 INFO] epoch: 004 - iter: 00400 - train loss: 0.9575 - time elapsed/per batch: 16.2851 0.0814
[Sat, 17 May 2025 07:02:45 INFO] epoch: 004 - iter: 00600 - train loss: 0.9353 - time elapsed/per batch: 13.3756 0.0669
[Sat, 17 May 2025 07:02:58 INFO] epoch: 004 - iter: 00800 - train loss: 0.9182 - time elapsed/per batch: 12.4963 0.0625
[Sat, 17 May 2025 07:03:12 INFO] epoch: 004 - iter: 01000 - train loss: 0.8813 - time elapsed/per batch: 14.1815 0.0709
[Sat, 17 May 2025 07:03:25 INFO] epoch: 004 - iter: 01200 - train loss: 0.9254 - time elapsed/per batch: 12.7150 0.0636
[Sat, 17 May 2025 07:03:37 INFO] epoch: 004 - iter: 01400 - train loss: 0.9291 - time elapsed/per batch: 12.7610 0.0638
[Sat, 17 May 2025 07:03:50 INFO] epoch: 004 - iter: 01600 - train loss: 0.9130 - time elapsed/per batch: 12.6746 0.0634
[Sat, 17 May 2025 07:04:02 INFO] epoch: 004 - iter: 01800 - train loss: 0.9320 - time elapsed/per batch: 12.2696 0.0613
[Sat, 17 May 2025 07:04:15 INFO] epoch: 004 - iter: 02000 - train loss: 0.9642 - time elapsed/per batch: 12.1460 0.0607
[Sat, 17 May 2025 07:04:30 INFO] epoch: 004 - iter: 02200 - train loss: 0.9021 - time elapsed/per batch: 15.0369 0.0752
[Sat, 17 May 2025 07:04:42 INFO] epoch: 004 - iter: 02400 - train loss: 0.9122 - time elapsed/per batch: 12.4915 0.0625
[Sat, 17 May 2025 07:04:54 INFO] epoch: 004 - iter: 02600 - train loss: 0.9219 - time elapsed/per batch: 12.3031 0.0615
[Sat, 17 May 2025 07:05:07 INFO] epoch: 004 - iter: 02800 - train loss: 0.9143 - time elapsed/per batch: 12.7790 0.0639
[Sat, 17 May 2025 07:05:20 INFO] epoch: 004 - iter: 03000 - train loss: 0.8779 - time elapsed/per batch: 12.9738 0.0649
[Sat, 17 May 2025 07:05:32 INFO] epoch: 004 - iter: 03200 - train loss: 0.9001 - time elapsed/per batch: 12.2690 0.0613
[Sat, 17 May 2025 07:05:46 INFO] epoch: 004 - iter: 03400 - train loss: 0.9194 - time elapsed/per batch: 13.5910 0.0680
[Sat, 17 May 2025 07:05:59 INFO] epoch: 004 - iter: 03600 - train loss: 0.9024 - time elapsed/per batch: 12.9436 0.0647
[Sat, 17 May 2025 07:06:13 INFO] epoch: 004 - iter: 03800 - train loss: 0.9204 - time elapsed/per batch: 13.6570 0.0683
[Sat, 17 May 2025 07:06:26 INFO] epoch: 004 - iter: 04000 - train loss: 0.9292 - time elapsed/per batch: 13.4725 0.0674
[Sat, 17 May 2025 07:06:38 INFO] epoch: 004 - iter: 04200 - train loss: 0.9644 - time elapsed/per batch: 12.2835 0.0614
[Sat, 17 May 2025 07:06:51 INFO] epoch: 004 - iter: 04400 - train loss: 0.8977 - time elapsed/per batch: 12.5670 0.0628
[Sat, 17 May 2025 07:07:04 INFO] epoch: 004 - iter: 04600 - train loss: 0.9058 - time elapsed/per batch: 12.6380 0.0632
[Sat, 17 May 2025 07:07:18 INFO] epoch: 004 - iter: 04800 - train loss: 0.9143 - time elapsed/per batch: 14.5350 0.0727
[Sat, 17 May 2025 07:07:33 INFO] epoch: 004 - iter: 05000 - train loss: 0.8997 - time elapsed/per batch: 14.6648 0.0733
[Sat, 17 May 2025 07:07:45 INFO] epoch: 004 - iter: 05200 - train loss: 0.9187 - time elapsed/per batch: 12.3280 0.0616
[Sat, 17 May 2025 07:07:58 INFO] epoch: 004 - iter: 05400 - train loss: 0.8782 - time elapsed/per batch: 12.9430 0.0647
[Sat, 17 May 2025 07:08:11 INFO] epoch: 004 - iter: 05600 - train loss: 0.8940 - time elapsed/per batch: 12.7122 0.0636
[Sat, 17 May 2025 07:08:48 INFO] epoch: 004 - iter: 05745 - valid loss: 3.7475 - bleu score: 0.0733 - full evaluation time: 28.4470
[Sat, 17 May 2025 07:09:01 INFO] epoch: 005 - iter: 00200 - train loss: 0.8871 - time elapsed/per batch: 13.0301 0.0652
[Sat, 17 May 2025 07:09:14 INFO] epoch: 005 - iter: 00400 - train loss: 0.8989 - time elapsed/per batch: 12.4275 0.0621
[Sat, 17 May 2025 07:09:26 INFO] epoch: 005 - iter: 00600 - train loss: 0.8978 - time elapsed/per batch: 12.3735 0.0619
[Sat, 17 May 2025 07:09:41 INFO] epoch: 005 - iter: 00800 - train loss: 0.8884 - time elapsed/per batch: 14.5045 0.0725
[Sat, 17 May 2025 07:09:53 INFO] epoch: 005 - iter: 01000 - train loss: 0.9170 - time elapsed/per batch: 12.2580 0.0613
[Sat, 17 May 2025 07:10:05 INFO] epoch: 005 - iter: 01200 - train loss: 0.8887 - time elapsed/per batch: 12.4465 0.0622
[Sat, 17 May 2025 07:10:18 INFO] epoch: 005 - iter: 01400 - train loss: 0.9194 - time elapsed/per batch: 12.2480 0.0612
[Sat, 17 May 2025 07:10:30 INFO] epoch: 005 - iter: 01600 - train loss: 0.9158 - time elapsed/per batch: 12.0585 0.0603
[Sat, 17 May 2025 07:10:42 INFO] epoch: 005 - iter: 01800 - train loss: 0.8927 - time elapsed/per batch: 12.6750 0.0634
[Sat, 17 May 2025 07:10:57 INFO] epoch: 005 - iter: 02000 - train loss: 0.8741 - time elapsed/per batch: 14.7150 0.0736
[Sat, 17 May 2025 07:11:10 INFO] epoch: 005 - iter: 02200 - train loss: 0.8826 - time elapsed/per batch: 12.7360 0.0637
[Sat, 17 May 2025 07:11:23 INFO] epoch: 005 - iter: 02400 - train loss: 0.8833 - time elapsed/per batch: 12.8395 0.0642
[Sat, 17 May 2025 07:11:36 INFO] epoch: 005 - iter: 02600 - train loss: 0.8728 - time elapsed/per batch: 13.6040 0.0680
[Sat, 17 May 2025 07:11:49 INFO] epoch: 005 - iter: 02800 - train loss: 0.8580 - time elapsed/per batch: 12.8450 0.0642
[Sat, 17 May 2025 07:12:01 INFO] epoch: 005 - iter: 03000 - train loss: 0.8948 - time elapsed/per batch: 12.2570 0.0613
[Sat, 17 May 2025 07:12:15 INFO] epoch: 005 - iter: 03200 - train loss: 0.8941 - time elapsed/per batch: 13.9960 0.0700
[Sat, 17 May 2025 07:12:30 INFO] epoch: 005 - iter: 03400 - train loss: 0.8670 - time elapsed/per batch: 14.5160 0.0726
[Sat, 17 May 2025 07:12:43 INFO] epoch: 005 - iter: 03600 - train loss: 0.8773 - time elapsed/per batch: 13.7200 0.0686
[Sat, 17 May 2025 07:12:56 INFO] epoch: 005 - iter: 03800 - train loss: 0.9112 - time elapsed/per batch: 12.6795 0.0634
[Sat, 17 May 2025 07:13:10 INFO] epoch: 005 - iter: 04000 - train loss: 0.9017 - time elapsed/per batch: 13.6080 0.0680
[Sat, 17 May 2025 07:13:26 INFO] epoch: 005 - iter: 04200 - train loss: 0.8711 - time elapsed/per batch: 16.4810 0.0824
[Sat, 17 May 2025 07:13:39 INFO] epoch: 005 - iter: 04400 - train loss: 0.8777 - time elapsed/per batch: 13.0320 0.0652
[Sat, 17 May 2025 07:13:52 INFO] epoch: 005 - iter: 04600 - train loss: 0.8554 - time elapsed/per batch: 13.0615 0.0653
[Sat, 17 May 2025 07:14:05 INFO] epoch: 005 - iter: 04800 - train loss: 0.8842 - time elapsed/per batch: 13.0730 0.0654
[Sat, 17 May 2025 07:14:18 INFO] epoch: 005 - iter: 05000 - train loss: 0.8958 - time elapsed/per batch: 12.9120 0.0646
[Sat, 17 May 2025 07:14:31 INFO] epoch: 005 - iter: 05200 - train loss: 0.9020 - time elapsed/per batch: 12.5260 0.0626
[Sat, 17 May 2025 07:14:44 INFO] epoch: 005 - iter: 05400 - train loss: 0.8619 - time elapsed/per batch: 12.8045 0.0640
[Sat, 17 May 2025 07:14:58 INFO] epoch: 005 - iter: 05600 - train loss: 0.8695 - time elapsed/per batch: 14.3910 0.0720
[Sat, 17 May 2025 07:15:35 INFO] epoch: 005 - iter: 05745 - valid loss: 3.6733 - bleu score: 0.0805 - full evaluation time: 27.8860
[Sat, 17 May 2025 07:15:50 INFO] epoch: 006 - iter: 00200 - train loss: 0.8479 - time elapsed/per batch: 14.7640 0.0738
[Sat, 17 May 2025 07:16:03 INFO] epoch: 006 - iter: 00400 - train loss: 0.8761 - time elapsed/per batch: 13.5650 0.0678
[Sat, 17 May 2025 07:16:16 INFO] epoch: 006 - iter: 00600 - train loss: 0.8606 - time elapsed/per batch: 12.6930 0.0635
[Sat, 17 May 2025 07:16:31 INFO] epoch: 006 - iter: 00800 - train loss: 0.8422 - time elapsed/per batch: 14.6190 0.0731
[Sat, 17 May 2025 07:16:44 INFO] epoch: 006 - iter: 01000 - train loss: 0.8605 - time elapsed/per batch: 12.7760 0.0639
[Sat, 17 May 2025 07:16:56 INFO] epoch: 006 - iter: 01200 - train loss: 0.8742 - time elapsed/per batch: 12.1155 0.0606
[Sat, 17 May 2025 07:17:09 INFO] epoch: 006 - iter: 01400 - train loss: 0.8366 - time elapsed/per batch: 13.0280 0.0651
[Sat, 17 May 2025 07:17:22 INFO] epoch: 006 - iter: 01600 - train loss: 0.8673 - time elapsed/per batch: 13.6180 0.0681
[Sat, 17 May 2025 07:17:35 INFO] epoch: 006 - iter: 01800 - train loss: 0.8933 - time elapsed/per batch: 12.4135 0.0621
[Sat, 17 May 2025 07:17:47 INFO] epoch: 006 - iter: 02000 - train loss: 0.8561 - time elapsed/per batch: 12.3080 0.0615
[Sat, 17 May 2025 07:18:00 INFO] epoch: 006 - iter: 02200 - train loss: 0.8703 - time elapsed/per batch: 13.2220 0.0661
[Sat, 17 May 2025 07:18:13 INFO] epoch: 006 - iter: 02400 - train loss: 0.8587 - time elapsed/per batch: 12.7040 0.0635
[Sat, 17 May 2025 07:18:25 INFO] epoch: 006 - iter: 02600 - train loss: 0.8550 - time elapsed/per batch: 12.5170 0.0626
[Sat, 17 May 2025 07:18:38 INFO] epoch: 006 - iter: 02800 - train loss: 0.8567 - time elapsed/per batch: 12.4105 0.0621
[Sat, 17 May 2025 07:18:51 INFO] epoch: 006 - iter: 03000 - train loss: 0.8546 - time elapsed/per batch: 12.9780 0.0649
[Sat, 17 May 2025 07:19:04 INFO] epoch: 006 - iter: 03200 - train loss: 0.8524 - time elapsed/per batch: 12.8795 0.0644
[Sat, 17 May 2025 07:19:16 INFO] epoch: 006 - iter: 03400 - train loss: 0.8731 - time elapsed/per batch: 12.5195 0.0626
[Sat, 17 May 2025 07:19:30 INFO] epoch: 006 - iter: 03600 - train loss: 0.8765 - time elapsed/per batch: 13.5920 0.0680
[Sat, 17 May 2025 07:19:43 INFO] epoch: 006 - iter: 03800 - train loss: 0.8502 - time elapsed/per batch: 12.8855 0.0644
[Sat, 17 May 2025 07:19:55 INFO] epoch: 006 - iter: 04000 - train loss: 0.8533 - time elapsed/per batch: 12.5590 0.0628
[Sat, 17 May 2025 07:20:09 INFO] epoch: 006 - iter: 04200 - train loss: 0.8241 - time elapsed/per batch: 14.2080 0.0710
[Sat, 17 May 2025 07:20:23 INFO] epoch: 006 - iter: 04400 - train loss: 0.8491 - time elapsed/per batch: 13.8540 0.0693
[Sat, 17 May 2025 07:20:36 INFO] epoch: 006 - iter: 04600 - train loss: 0.8528 - time elapsed/per batch: 12.5530 0.0628
[Sat, 17 May 2025 07:20:51 INFO] epoch: 006 - iter: 04800 - train loss: 0.8506 - time elapsed/per batch: 14.6910 0.0735
[Sat, 17 May 2025 07:21:03 INFO] epoch: 006 - iter: 05000 - train loss: 0.8795 - time elapsed/per batch: 12.4770 0.0624
[Sat, 17 May 2025 07:21:17 INFO] epoch: 006 - iter: 05200 - train loss: 0.8802 - time elapsed/per batch: 13.9080 0.0695
[Sat, 17 May 2025 07:21:29 INFO] epoch: 006 - iter: 05400 - train loss: 0.8736 - time elapsed/per batch: 12.2220 0.0611
[Sat, 17 May 2025 07:21:44 INFO] epoch: 006 - iter: 05600 - train loss: 0.8619 - time elapsed/per batch: 14.6460 0.0732
[Sat, 17 May 2025 07:22:24 INFO] epoch: 006 - iter: 05745 - valid loss: 3.6237 - bleu score: 0.0830 - full evaluation time: 30.3270
[Sat, 17 May 2025 07:22:37 INFO] epoch: 007 - iter: 00200 - train loss: 0.8085 - time elapsed/per batch: 13.0190 0.0651
[Sat, 17 May 2025 07:22:50 INFO] epoch: 007 - iter: 00400 - train loss: 0.8302 - time elapsed/per batch: 12.8898 0.0644
[Sat, 17 May 2025 07:23:03 INFO] epoch: 007 - iter: 00600 - train loss: 0.8266 - time elapsed/per batch: 13.0515 0.0653
[Sat, 17 May 2025 07:23:16 INFO] epoch: 007 - iter: 00800 - train loss: 0.8166 - time elapsed/per batch: 12.9785 0.0649
[Sat, 17 May 2025 07:23:28 INFO] epoch: 007 - iter: 01000 - train loss: 0.8418 - time elapsed/per batch: 12.5040 0.0625
[Sat, 17 May 2025 07:23:41 INFO] epoch: 007 - iter: 01200 - train loss: 0.8491 - time elapsed/per batch: 12.7565 0.0638
[Sat, 17 May 2025 07:23:54 INFO] epoch: 007 - iter: 01400 - train loss: 0.8682 - time elapsed/per batch: 12.5370 0.0627
[Sat, 17 May 2025 07:24:07 INFO] epoch: 007 - iter: 01600 - train loss: 0.8300 - time elapsed/per batch: 12.9075 0.0645
[Sat, 17 May 2025 07:24:19 INFO] epoch: 007 - iter: 01800 - train loss: 0.8567 - time elapsed/per batch: 12.8330 0.0642
[Sat, 17 May 2025 07:24:32 INFO] epoch: 007 - iter: 02000 - train loss: 0.8522 - time elapsed/per batch: 12.2840 0.0614
[Sat, 17 May 2025 07:24:44 INFO] epoch: 007 - iter: 02200 - train loss: 0.8334 - time elapsed/per batch: 12.2815 0.0614
[Sat, 17 May 2025 07:24:59 INFO] epoch: 007 - iter: 02400 - train loss: 0.8623 - time elapsed/per batch: 15.4130 0.0771
[Sat, 17 May 2025 07:25:13 INFO] epoch: 007 - iter: 02600 - train loss: 0.8350 - time elapsed/per batch: 13.1885 0.0659
[Sat, 17 May 2025 07:25:25 INFO] epoch: 007 - iter: 02800 - train loss: 0.8565 - time elapsed/per batch: 12.2055 0.0610
[Sat, 17 May 2025 07:25:39 INFO] epoch: 007 - iter: 03000 - train loss: 0.8440 - time elapsed/per batch: 13.9550 0.0698
[Sat, 17 May 2025 07:25:55 INFO] epoch: 007 - iter: 03200 - train loss: 0.8219 - time elapsed/per batch: 16.0780 0.0804
[Sat, 17 May 2025 07:26:09 INFO] epoch: 007 - iter: 03400 - train loss: 0.8333 - time elapsed/per batch: 14.3525 0.0718
[Sat, 17 May 2025 07:26:24 INFO] epoch: 007 - iter: 03600 - train loss: 0.8276 - time elapsed/per batch: 14.7175 0.0736
[Sat, 17 May 2025 07:26:36 INFO] epoch: 007 - iter: 03800 - train loss: 0.8423 - time elapsed/per batch: 12.2915 0.0615
[Sat, 17 May 2025 07:26:48 INFO] epoch: 007 - iter: 04000 - train loss: 0.8674 - time elapsed/per batch: 12.1945 0.0610
[Sat, 17 May 2025 07:27:01 INFO] epoch: 007 - iter: 04200 - train loss: 0.8381 - time elapsed/per batch: 12.6230 0.0631
[Sat, 17 May 2025 07:27:15 INFO] epoch: 007 - iter: 04400 - train loss: 0.8507 - time elapsed/per batch: 14.1490 0.0707
[Sat, 17 May 2025 07:27:28 INFO] epoch: 007 - iter: 04600 - train loss: 0.8214 - time elapsed/per batch: 12.7395 0.0637
[Sat, 17 May 2025 07:27:42 INFO] epoch: 007 - iter: 04800 - train loss: 0.8406 - time elapsed/per batch: 14.6430 0.0732
[Sat, 17 May 2025 07:27:56 INFO] epoch: 007 - iter: 05000 - train loss: 0.8168 - time elapsed/per batch: 13.6660 0.0683
[Sat, 17 May 2025 07:28:09 INFO] epoch: 007 - iter: 05200 - train loss: 0.8317 - time elapsed/per batch: 12.7680 0.0638
[Sat, 17 May 2025 07:28:23 INFO] epoch: 007 - iter: 05400 - train loss: 0.8550 - time elapsed/per batch: 13.8770 0.0694
[Sat, 17 May 2025 07:28:35 INFO] epoch: 007 - iter: 05600 - train loss: 0.8534 - time elapsed/per batch: 12.2930 0.0615
[Sat, 17 May 2025 07:29:14 INFO] epoch: 007 - iter: 05745 - valid loss: 3.5974 - bleu score: 0.0907 - full evaluation time: 30.0640
[Sat, 17 May 2025 07:29:28 INFO] epoch: 008 - iter: 00200 - train loss: 0.8407 - time elapsed/per batch: 14.1835 0.0709
[Sat, 17 May 2025 07:29:41 INFO] epoch: 008 - iter: 00400 - train loss: 0.8180 - time elapsed/per batch: 12.5095 0.0625
[Sat, 17 May 2025 07:29:53 INFO] epoch: 008 - iter: 00600 - train loss: 0.8466 - time elapsed/per batch: 12.2265 0.0611
[Sat, 17 May 2025 07:30:06 INFO] epoch: 008 - iter: 00800 - train loss: 0.8131 - time elapsed/per batch: 12.7400 0.0637
[Sat, 17 May 2025 07:30:18 INFO] epoch: 008 - iter: 01000 - train loss: 0.8198 - time elapsed/per batch: 12.5650 0.0628
[Sat, 17 May 2025 07:30:34 INFO] epoch: 008 - iter: 01200 - train loss: 0.8172 - time elapsed/per batch: 15.4860 0.0774
[Sat, 17 May 2025 07:30:47 INFO] epoch: 008 - iter: 01400 - train loss: 0.8354 - time elapsed/per batch: 13.0710 0.0654
[Sat, 17 May 2025 07:31:00 INFO] epoch: 008 - iter: 01600 - train loss: 0.8036 - time elapsed/per batch: 12.7905 0.0640
[Sat, 17 May 2025 07:31:14 INFO] epoch: 008 - iter: 01800 - train loss: 0.8197 - time elapsed/per batch: 14.4735 0.0724
[Sat, 17 May 2025 07:31:27 INFO] epoch: 008 - iter: 02000 - train loss: 0.8541 - time elapsed/per batch: 12.6990 0.0635
[Sat, 17 May 2025 07:31:39 INFO] epoch: 008 - iter: 02200 - train loss: 0.8260 - time elapsed/per batch: 12.1465 0.0607
[Sat, 17 May 2025 07:31:52 INFO] epoch: 008 - iter: 02400 - train loss: 0.8294 - time elapsed/per batch: 12.7200 0.0636
[Sat, 17 May 2025 07:32:04 INFO] epoch: 008 - iter: 02600 - train loss: 0.8278 - time elapsed/per batch: 12.5330 0.0627
[Sat, 17 May 2025 07:32:17 INFO] epoch: 008 - iter: 02800 - train loss: 0.8242 - time elapsed/per batch: 12.9055 0.0645
[Sat, 17 May 2025 07:32:31 INFO] epoch: 008 - iter: 03000 - train loss: 0.8126 - time elapsed/per batch: 13.9320 0.0697
[Sat, 17 May 2025 07:32:44 INFO] epoch: 008 - iter: 03200 - train loss: 0.8216 - time elapsed/per batch: 12.6115 0.0631
[Sat, 17 May 2025 07:32:56 INFO] epoch: 008 - iter: 03400 - train loss: 0.8185 - time elapsed/per batch: 12.5720 0.0629
[Sat, 17 May 2025 07:33:10 INFO] epoch: 008 - iter: 03600 - train loss: 0.8214 - time elapsed/per batch: 13.5950 0.0680
[Sat, 17 May 2025 07:33:23 INFO] epoch: 008 - iter: 03800 - train loss: 0.8115 - time elapsed/per batch: 12.6445 0.0632
[Sat, 17 May 2025 07:33:35 INFO] epoch: 008 - iter: 04000 - train loss: 0.8214 - time elapsed/per batch: 12.5236 0.0626
[Sat, 17 May 2025 07:33:48 INFO] epoch: 008 - iter: 04200 - train loss: 0.8173 - time elapsed/per batch: 12.6506 0.0633
[Sat, 17 May 2025 07:34:02 INFO] epoch: 008 - iter: 04400 - train loss: 0.8257 - time elapsed/per batch: 13.7078 0.0685
[Sat, 17 May 2025 07:34:14 INFO] epoch: 008 - iter: 04600 - train loss: 0.8075 - time elapsed/per batch: 12.7371 0.0637
[Sat, 17 May 2025 07:34:27 INFO] epoch: 008 - iter: 04800 - train loss: 0.8254 - time elapsed/per batch: 12.6744 0.0634
[Sat, 17 May 2025 07:34:42 INFO] epoch: 008 - iter: 05000 - train loss: 0.8063 - time elapsed/per batch: 15.0206 0.0751
[Sat, 17 May 2025 07:34:56 INFO] epoch: 008 - iter: 05200 - train loss: 0.8127 - time elapsed/per batch: 14.3604 0.0718
[Sat, 17 May 2025 07:35:10 INFO] epoch: 008 - iter: 05400 - train loss: 0.7961 - time elapsed/per batch: 14.1312 0.0707
[Sat, 17 May 2025 07:35:23 INFO] epoch: 008 - iter: 05600 - train loss: 0.8425 - time elapsed/per batch: 12.5667 0.0628
[Sat, 17 May 2025 07:36:01 INFO] epoch: 008 - iter: 05745 - valid loss: 3.5671 - bleu score: 0.0952 - full evaluation time: 29.4475
[Sat, 17 May 2025 07:36:14 INFO] epoch: 009 - iter: 00200 - train loss: 0.7777 - time elapsed/per batch: 12.7693 0.0638
[Sat, 17 May 2025 07:36:29 INFO] epoch: 009 - iter: 00400 - train loss: 0.8106 - time elapsed/per batch: 14.6283 0.0731
[Sat, 17 May 2025 07:36:41 INFO] epoch: 009 - iter: 00600 - train loss: 0.8050 - time elapsed/per batch: 12.4391 0.0622
[Sat, 17 May 2025 07:36:54 INFO] epoch: 009 - iter: 00800 - train loss: 0.7862 - time elapsed/per batch: 12.9234 0.0646
[Sat, 17 May 2025 07:37:07 INFO] epoch: 009 - iter: 01000 - train loss: 0.8338 - time elapsed/per batch: 12.4471 0.0622
[Sat, 17 May 2025 07:37:20 INFO] epoch: 009 - iter: 01200 - train loss: 0.8000 - time elapsed/per batch: 12.8526 0.0643
[Sat, 17 May 2025 07:37:32 INFO] epoch: 009 - iter: 01400 - train loss: 0.8176 - time elapsed/per batch: 12.4393 0.0622
[Sat, 17 May 2025 07:37:44 INFO] epoch: 009 - iter: 01600 - train loss: 0.8167 - time elapsed/per batch: 12.2348 0.0612
[Sat, 17 May 2025 07:37:56 INFO] epoch: 009 - iter: 01800 - train loss: 0.8285 - time elapsed/per batch: 12.2089 0.0610
[Sat, 17 May 2025 07:38:08 INFO] epoch: 009 - iter: 02000 - train loss: 0.8260 - time elapsed/per batch: 11.9657 0.0598
[Sat, 17 May 2025 07:38:21 INFO] epoch: 009 - iter: 02200 - train loss: 0.8018 - time elapsed/per batch: 12.6345 0.0632
[Sat, 17 May 2025 07:38:35 INFO] epoch: 009 - iter: 02400 - train loss: 0.7928 - time elapsed/per batch: 13.7200 0.0686
[Sat, 17 May 2025 07:38:47 INFO] epoch: 009 - iter: 02600 - train loss: 0.8241 - time elapsed/per batch: 12.5082 0.0625
[Sat, 17 May 2025 07:39:00 INFO] epoch: 009 - iter: 02800 - train loss: 0.8083 - time elapsed/per batch: 12.3462 0.0617
[Sat, 17 May 2025 07:39:13 INFO] epoch: 009 - iter: 03000 - train loss: 0.8049 - time elapsed/per batch: 13.0212 0.0651
[Sat, 17 May 2025 07:39:27 INFO] epoch: 009 - iter: 03200 - train loss: 0.8025 - time elapsed/per batch: 14.5024 0.0725
[Sat, 17 May 2025 07:39:42 INFO] epoch: 009 - iter: 03400 - train loss: 0.8104 - time elapsed/per batch: 14.7650 0.0738
[Sat, 17 May 2025 07:39:57 INFO] epoch: 009 - iter: 03600 - train loss: 0.8137 - time elapsed/per batch: 14.9717 0.0749
[Sat, 17 May 2025 07:40:09 INFO] epoch: 009 - iter: 03800 - train loss: 0.8222 - time elapsed/per batch: 12.1432 0.0607
[Sat, 17 May 2025 07:40:22 INFO] epoch: 009 - iter: 04000 - train loss: 0.8120 - time elapsed/per batch: 12.6817 0.0634
[Sat, 17 May 2025 07:40:36 INFO] epoch: 009 - iter: 04200 - train loss: 0.8018 - time elapsed/per batch: 13.9541 0.0698
[Sat, 17 May 2025 07:40:51 INFO] epoch: 009 - iter: 04400 - train loss: 0.7977 - time elapsed/per batch: 15.8668 0.0793
[Sat, 17 May 2025 07:41:06 INFO] epoch: 009 - iter: 04600 - train loss: 0.8117 - time elapsed/per batch: 14.7727 0.0739
[Sat, 17 May 2025 07:41:19 INFO] epoch: 009 - iter: 04800 - train loss: 0.8055 - time elapsed/per batch: 12.4432 0.0622
[Sat, 17 May 2025 07:41:31 INFO] epoch: 009 - iter: 05000 - train loss: 0.8203 - time elapsed/per batch: 12.6036 0.0630
[Sat, 17 May 2025 07:41:44 INFO] epoch: 009 - iter: 05200 - train loss: 0.8003 - time elapsed/per batch: 12.2792 0.0614
[Sat, 17 May 2025 07:41:57 INFO] epoch: 009 - iter: 05400 - train loss: 0.7882 - time elapsed/per batch: 13.0625 0.0653
[Sat, 17 May 2025 07:42:09 INFO] epoch: 009 - iter: 05600 - train loss: 0.8039 - time elapsed/per batch: 12.7707 0.0639
[Sat, 17 May 2025 07:42:47 INFO] epoch: 009 - iter: 05745 - valid loss: 3.5447 - bleu score: 0.0980 - full evaluation time: 27.2758
[Sat, 17 May 2025 07:42:59 INFO] epoch: 010 - iter: 00200 - train loss: 0.7975 - time elapsed/per batch: 12.5078 0.0625
[Sat, 17 May 2025 07:43:12 INFO] epoch: 010 - iter: 00400 - train loss: 0.8153 - time elapsed/per batch: 12.2026 0.0610
[Sat, 17 May 2025 07:43:24 INFO] epoch: 010 - iter: 00600 - train loss: 0.7744 - time elapsed/per batch: 12.9162 0.0646
[Sat, 17 May 2025 07:43:37 INFO] epoch: 010 - iter: 00800 - train loss: 0.7951 - time elapsed/per batch: 12.8021 0.0640
[Sat, 17 May 2025 07:43:51 INFO] epoch: 010 - iter: 01000 - train loss: 0.8139 - time elapsed/per batch: 13.9540 0.0698
[Sat, 17 May 2025 07:44:04 INFO] epoch: 010 - iter: 01200 - train loss: 0.7823 - time elapsed/per batch: 12.6660 0.0633
[Sat, 17 May 2025 07:44:16 INFO] epoch: 010 - iter: 01400 - train loss: 0.8100 - time elapsed/per batch: 12.5125 0.0626
[Sat, 17 May 2025 07:44:31 INFO] epoch: 010 - iter: 01600 - train loss: 0.8003 - time elapsed/per batch: 14.4675 0.0723
[Sat, 17 May 2025 07:44:44 INFO] epoch: 010 - iter: 01800 - train loss: 0.8022 - time elapsed/per batch: 12.6260 0.0631
[Sat, 17 May 2025 07:44:56 INFO] epoch: 010 - iter: 02000 - train loss: 0.8032 - time elapsed/per batch: 12.5990 0.0630
[Sat, 17 May 2025 07:45:10 INFO] epoch: 010 - iter: 02200 - train loss: 0.7946 - time elapsed/per batch: 13.5040 0.0675
[Sat, 17 May 2025 07:45:23 INFO] epoch: 010 - iter: 02400 - train loss: 0.7940 - time elapsed/per batch: 13.7730 0.0689
[Sat, 17 May 2025 07:45:36 INFO] epoch: 010 - iter: 02600 - train loss: 0.8126 - time elapsed/per batch: 12.7280 0.0636
[Sat, 17 May 2025 07:45:48 INFO] epoch: 010 - iter: 02800 - train loss: 0.8091 - time elapsed/per batch: 12.2750 0.0614
[Sat, 17 May 2025 07:46:01 INFO] epoch: 010 - iter: 03000 - train loss: 0.8168 - time elapsed/per batch: 12.1630 0.0608
[Sat, 17 May 2025 07:46:15 INFO] epoch: 010 - iter: 03200 - train loss: 0.7889 - time elapsed/per batch: 14.5905 0.0730
[Sat, 17 May 2025 07:46:29 INFO] epoch: 010 - iter: 03400 - train loss: 0.8083 - time elapsed/per batch: 13.5790 0.0679
[Sat, 17 May 2025 07:46:41 INFO] epoch: 010 - iter: 03600 - train loss: 0.7922 - time elapsed/per batch: 12.6520 0.0633
[Sat, 17 May 2025 07:46:56 INFO] epoch: 010 - iter: 03800 - train loss: 0.7772 - time elapsed/per batch: 14.9340 0.0747
[Sat, 17 May 2025 07:47:11 INFO] epoch: 010 - iter: 04000 - train loss: 0.8077 - time elapsed/per batch: 15.0180 0.0751
[Sat, 17 May 2025 07:47:27 INFO] epoch: 010 - iter: 04200 - train loss: 0.8278 - time elapsed/per batch: 15.4920 0.0775
[Sat, 17 May 2025 07:47:41 INFO] epoch: 010 - iter: 04400 - train loss: 0.7777 - time elapsed/per batch: 13.9875 0.0699
[Sat, 17 May 2025 07:47:55 INFO] epoch: 010 - iter: 04600 - train loss: 0.7981 - time elapsed/per batch: 13.7050 0.0685
[Sat, 17 May 2025 07:48:10 INFO] epoch: 010 - iter: 04800 - train loss: 0.8123 - time elapsed/per batch: 15.4375 0.0772
[Sat, 17 May 2025 07:48:24 INFO] epoch: 010 - iter: 05000 - train loss: 0.7956 - time elapsed/per batch: 13.5670 0.0678
[Sat, 17 May 2025 07:48:37 INFO] epoch: 010 - iter: 05200 - train loss: 0.7984 - time elapsed/per batch: 13.8850 0.0694
[Sat, 17 May 2025 07:48:51 INFO] epoch: 010 - iter: 05400 - train loss: 0.7858 - time elapsed/per batch: 13.6610 0.0683
[Sat, 17 May 2025 07:49:04 INFO] epoch: 010 - iter: 05600 - train loss: 0.8258 - time elapsed/per batch: 13.3130 0.0666
[Sat, 17 May 2025 07:49:47 INFO] epoch: 010 - iter: 05745 - valid loss: 3.5233 - bleu score: 0.1052 - full evaluation time: 32.8060
[Sat, 17 May 2025 07:50:02 INFO] epoch: 011 - iter: 00200 - train loss: 0.7943 - time elapsed/per batch: 14.6320 0.0732
[Sat, 17 May 2025 07:50:20 INFO] epoch: 011 - iter: 00400 - train loss: 0.7692 - time elapsed/per batch: 18.3814 0.0919
[Sat, 17 May 2025 07:50:38 INFO] epoch: 011 - iter: 00600 - train loss: 0.7879 - time elapsed/per batch: 17.3295 0.0866
[Sat, 17 May 2025 07:50:51 INFO] epoch: 011 - iter: 00800 - train loss: 0.7797 - time elapsed/per batch: 13.6935 0.0685
[Sat, 17 May 2025 07:51:05 INFO] epoch: 011 - iter: 01000 - train loss: 0.7974 - time elapsed/per batch: 13.5615 0.0678
[Sat, 17 May 2025 07:51:21 INFO] epoch: 011 - iter: 01200 - train loss: 0.7887 - time elapsed/per batch: 15.6480 0.0782
[Sat, 17 May 2025 07:51:34 INFO] epoch: 011 - iter: 01400 - train loss: 0.7784 - time elapsed/per batch: 13.4970 0.0675
[Sat, 17 May 2025 07:51:48 INFO] epoch: 011 - iter: 01600 - train loss: 0.7942 - time elapsed/per batch: 13.8710 0.0694
[Sat, 17 May 2025 07:52:02 INFO] epoch: 011 - iter: 01800 - train loss: 0.8026 - time elapsed/per batch: 13.7360 0.0687
[Sat, 17 May 2025 07:52:15 INFO] epoch: 011 - iter: 02000 - train loss: 0.7961 - time elapsed/per batch: 13.8210 0.0691
[Sat, 17 May 2025 07:52:29 INFO] epoch: 011 - iter: 02200 - train loss: 0.7855 - time elapsed/per batch: 13.8480 0.0692
[Sat, 17 May 2025 07:52:43 INFO] epoch: 011 - iter: 02400 - train loss: 0.8071 - time elapsed/per batch: 13.4235 0.0671
[Sat, 17 May 2025 07:52:58 INFO] epoch: 011 - iter: 02600 - train loss: 0.7843 - time elapsed/per batch: 15.7805 0.0789
[Sat, 17 May 2025 07:53:12 INFO] epoch: 011 - iter: 02800 - train loss: 0.7762 - time elapsed/per batch: 13.7350 0.0687
[Sat, 17 May 2025 07:53:26 INFO] epoch: 011 - iter: 03000 - train loss: 0.7852 - time elapsed/per batch: 13.5380 0.0677
[Sat, 17 May 2025 07:53:39 INFO] epoch: 011 - iter: 03200 - train loss: 0.7758 - time elapsed/per batch: 13.6315 0.0682
[Sat, 17 May 2025 07:53:57 INFO] epoch: 011 - iter: 03400 - train loss: 0.7830 - time elapsed/per batch: 17.2240 0.0861
[Sat, 17 May 2025 07:54:11 INFO] epoch: 011 - iter: 03600 - train loss: 0.7907 - time elapsed/per batch: 13.9020 0.0695
[Sat, 17 May 2025 07:54:24 INFO] epoch: 011 - iter: 03800 - train loss: 0.7814 - time elapsed/per batch: 13.6790 0.0684
[Sat, 17 May 2025 07:54:41 INFO] epoch: 011 - iter: 04000 - train loss: 0.8033 - time elapsed/per batch: 16.4060 0.0820
[Sat, 17 May 2025 07:54:56 INFO] epoch: 011 - iter: 04200 - train loss: 0.7791 - time elapsed/per batch: 15.7527 0.0788
[Sat, 17 May 2025 07:55:13 INFO] epoch: 011 - iter: 04400 - train loss: 0.7897 - time elapsed/per batch: 16.8644 0.0843
[Sat, 17 May 2025 07:55:27 INFO] epoch: 011 - iter: 04600 - train loss: 0.7898 - time elapsed/per batch: 13.7811 0.0689
[Sat, 17 May 2025 07:55:41 INFO] epoch: 011 - iter: 04800 - train loss: 0.7977 - time elapsed/per batch: 13.7030 0.0685
[Sat, 17 May 2025 07:55:56 INFO] epoch: 011 - iter: 05000 - train loss: 0.7981 - time elapsed/per batch: 14.9115 0.0746
[Sat, 17 May 2025 07:56:10 INFO] epoch: 011 - iter: 05200 - train loss: 0.7841 - time elapsed/per batch: 14.8560 0.0743
[Sat, 17 May 2025 07:56:24 INFO] epoch: 011 - iter: 05400 - train loss: 0.7942 - time elapsed/per batch: 13.7725 0.0689
[Sat, 17 May 2025 07:56:38 INFO] epoch: 011 - iter: 05600 - train loss: 0.7965 - time elapsed/per batch: 13.6880 0.0684
[Sat, 17 May 2025 07:57:16 INFO] epoch: 011 - iter: 05745 - valid loss: 3.5140 - bleu score: 0.1075 - full evaluation time: 28.0300
[Sat, 17 May 2025 07:57:30 INFO] epoch: 012 - iter: 00200 - train loss: 0.7706 - time elapsed/per batch: 14.1620 0.0708
[Sat, 17 May 2025 07:57:44 INFO] epoch: 012 - iter: 00400 - train loss: 0.7790 - time elapsed/per batch: 13.5590 0.0678
[Sat, 17 May 2025 07:57:58 INFO] epoch: 012 - iter: 00600 - train loss: 0.7986 - time elapsed/per batch: 13.9305 0.0697
[Sat, 17 May 2025 07:58:13 INFO] epoch: 012 - iter: 00800 - train loss: 0.7511 - time elapsed/per batch: 15.3390 0.0767
[Sat, 17 May 2025 07:58:27 INFO] epoch: 012 - iter: 01000 - train loss: 0.7882 - time elapsed/per batch: 14.1075 0.0705
[Sat, 17 May 2025 07:58:41 INFO] epoch: 012 - iter: 01200 - train loss: 0.7724 - time elapsed/per batch: 13.6315 0.0682
[Sat, 17 May 2025 07:58:54 INFO] epoch: 012 - iter: 01400 - train loss: 0.7899 - time elapsed/per batch: 13.6530 0.0683
[Sat, 17 May 2025 07:59:09 INFO] epoch: 012 - iter: 01600 - train loss: 0.7980 - time elapsed/per batch: 15.1751 0.0759
[Sat, 17 May 2025 07:59:23 INFO] epoch: 012 - iter: 01800 - train loss: 0.7849 - time elapsed/per batch: 13.3510 0.0668
[Sat, 17 May 2025 07:59:37 INFO] epoch: 012 - iter: 02000 - train loss: 0.7901 - time elapsed/per batch: 13.9580 0.0698
[Sat, 17 May 2025 07:59:50 INFO] epoch: 012 - iter: 02200 - train loss: 0.8092 - time elapsed/per batch: 13.6030 0.0680
[Sat, 17 May 2025 08:00:06 INFO] epoch: 012 - iter: 02400 - train loss: 0.7832 - time elapsed/per batch: 15.4210 0.0771
[Sat, 17 May 2025 08:00:19 INFO] epoch: 012 - iter: 02600 - train loss: 0.8174 - time elapsed/per batch: 13.3210 0.0666
[Sat, 17 May 2025 08:00:34 INFO] epoch: 012 - iter: 02800 - train loss: 0.7888 - time elapsed/per batch: 15.0925 0.0755
[Sat, 17 May 2025 08:00:49 INFO] epoch: 012 - iter: 03000 - train loss: 0.8010 - time elapsed/per batch: 15.2120 0.0761
[Sat, 17 May 2025 08:01:03 INFO] epoch: 012 - iter: 03200 - train loss: 0.7664 - time elapsed/per batch: 14.0140 0.0701
[Sat, 17 May 2025 08:01:17 INFO] epoch: 012 - iter: 03400 - train loss: 0.7787 - time elapsed/per batch: 13.7800 0.0689
[Sat, 17 May 2025 08:01:32 INFO] epoch: 012 - iter: 03600 - train loss: 0.7768 - time elapsed/per batch: 14.9840 0.0749
[Sat, 17 May 2025 08:01:46 INFO] epoch: 012 - iter: 03800 - train loss: 0.7833 - time elapsed/per batch: 13.7010 0.0685
[Sat, 17 May 2025 08:02:01 INFO] epoch: 012 - iter: 04000 - train loss: 0.7900 - time elapsed/per batch: 14.6660 0.0733
[Sat, 17 May 2025 08:02:14 INFO] epoch: 012 - iter: 04200 - train loss: 0.7675 - time elapsed/per batch: 13.5900 0.0679
[Sat, 17 May 2025 08:02:29 INFO] epoch: 012 - iter: 04400 - train loss: 0.7602 - time elapsed/per batch: 14.5165 0.0726
[Sat, 17 May 2025 08:02:43 INFO] epoch: 012 - iter: 04600 - train loss: 0.7873 - time elapsed/per batch: 14.3340 0.0717
[Sat, 17 May 2025 08:02:58 INFO] epoch: 012 - iter: 04800 - train loss: 0.7773 - time elapsed/per batch: 14.8850 0.0744
[Sat, 17 May 2025 08:03:12 INFO] epoch: 012 - iter: 05000 - train loss: 0.8117 - time elapsed/per batch: 14.5885 0.0729
[Sat, 17 May 2025 08:03:26 INFO] epoch: 012 - iter: 05200 - train loss: 0.7779 - time elapsed/per batch: 13.7030 0.0685
[Sat, 17 May 2025 08:03:42 INFO] epoch: 012 - iter: 05400 - train loss: 0.7713 - time elapsed/per batch: 16.0225 0.0801
[Sat, 17 May 2025 08:03:56 INFO] epoch: 012 - iter: 05600 - train loss: 0.8003 - time elapsed/per batch: 13.4190 0.0671
[Sat, 17 May 2025 08:04:36 INFO] epoch: 012 - iter: 05745 - valid loss: 3.4892 - bleu score: 0.1073 - full evaluation time: 29.7731
[Sat, 17 May 2025 08:04:50 INFO] epoch: 013 - iter: 00200 - train loss: 0.7693 - time elapsed/per batch: 14.2100 0.0710
[Sat, 17 May 2025 08:05:04 INFO] epoch: 013 - iter: 00400 - train loss: 0.7748 - time elapsed/per batch: 13.9020 0.0695
[Sat, 17 May 2025 08:05:19 INFO] epoch: 013 - iter: 00600 - train loss: 0.7756 - time elapsed/per batch: 15.4319 0.0772
[Sat, 17 May 2025 08:05:33 INFO] epoch: 013 - iter: 00800 - train loss: 0.7538 - time elapsed/per batch: 13.7250 0.0686
[Sat, 17 May 2025 08:05:48 INFO] epoch: 013 - iter: 01000 - train loss: 0.7450 - time elapsed/per batch: 15.0422 0.0752
[Sat, 17 May 2025 08:06:02 INFO] epoch: 013 - iter: 01200 - train loss: 0.7594 - time elapsed/per batch: 13.7580 0.0688
[Sat, 17 May 2025 08:06:15 INFO] epoch: 013 - iter: 01400 - train loss: 0.7880 - time elapsed/per batch: 13.3500 0.0667
[Sat, 17 May 2025 08:06:28 INFO] epoch: 013 - iter: 01600 - train loss: 0.7945 - time elapsed/per batch: 13.3380 0.0667
[Sat, 17 May 2025 08:06:42 INFO] epoch: 013 - iter: 01800 - train loss: 0.7537 - time elapsed/per batch: 14.1300 0.0707
[Sat, 17 May 2025 08:06:56 INFO] epoch: 013 - iter: 02000 - train loss: 0.7564 - time elapsed/per batch: 13.7020 0.0685
[Sat, 17 May 2025 08:07:11 INFO] epoch: 013 - iter: 02200 - train loss: 0.7692 - time elapsed/per batch: 14.9175 0.0746
[Sat, 17 May 2025 08:07:25 INFO] epoch: 013 - iter: 02400 - train loss: 0.7781 - time elapsed/per batch: 13.6050 0.0680
[Sat, 17 May 2025 08:07:39 INFO] epoch: 013 - iter: 02600 - train loss: 0.7796 - time elapsed/per batch: 14.6710 0.0734
[Sat, 17 May 2025 08:07:53 INFO] epoch: 013 - iter: 02800 - train loss: 0.7625 - time elapsed/per batch: 13.9220 0.0696
[Sat, 17 May 2025 08:08:07 INFO] epoch: 013 - iter: 03000 - train loss: 0.7655 - time elapsed/per batch: 13.3450 0.0667
[Sat, 17 May 2025 08:08:21 INFO] epoch: 013 - iter: 03200 - train loss: 0.7621 - time elapsed/per batch: 14.7750 0.0739
[Sat, 17 May 2025 08:08:35 INFO] epoch: 013 - iter: 03400 - train loss: 0.7560 - time elapsed/per batch: 13.9353 0.0697
[Sat, 17 May 2025 08:08:49 INFO] epoch: 013 - iter: 03600 - train loss: 0.7798 - time elapsed/per batch: 13.6100 0.0680
[Sat, 17 May 2025 08:09:04 INFO] epoch: 013 - iter: 03800 - train loss: 0.7638 - time elapsed/per batch: 14.8120 0.0741
[Sat, 17 May 2025 08:09:22 INFO] epoch: 013 - iter: 04000 - train loss: 0.7664 - time elapsed/per batch: 17.9920 0.0900
[Sat, 17 May 2025 08:09:36 INFO] epoch: 013 - iter: 04200 - train loss: 0.7797 - time elapsed/per batch: 13.8920 0.0695
[Sat, 17 May 2025 08:09:52 INFO] epoch: 013 - iter: 04400 - train loss: 0.7592 - time elapsed/per batch: 16.3085 0.0815
[Sat, 17 May 2025 08:10:05 INFO] epoch: 013 - iter: 04600 - train loss: 0.7935 - time elapsed/per batch: 13.3725 0.0669
[Sat, 17 May 2025 08:10:21 INFO] epoch: 013 - iter: 04800 - train loss: 0.7688 - time elapsed/per batch: 15.8735 0.0794
[Sat, 17 May 2025 08:10:36 INFO] epoch: 013 - iter: 05000 - train loss: 0.7658 - time elapsed/per batch: 14.8270 0.0741
[Sat, 17 May 2025 08:10:50 INFO] epoch: 013 - iter: 05200 - train loss: 0.7934 - time elapsed/per batch: 13.5205 0.0676
[Sat, 17 May 2025 08:11:03 INFO] epoch: 013 - iter: 05400 - train loss: 0.7953 - time elapsed/per batch: 13.4985 0.0675
[Sat, 17 May 2025 08:11:17 INFO] epoch: 013 - iter: 05600 - train loss: 0.7562 - time elapsed/per batch: 14.1960 0.0710
[Sat, 17 May 2025 08:11:56 INFO] epoch: 013 - iter: 05745 - valid loss: 3.4851 - bleu score: 0.1102 - full evaluation time: 29.0155
[Sat, 17 May 2025 08:12:12 INFO] epoch: 014 - iter: 00200 - train loss: 0.7744 - time elapsed/per batch: 15.9195 0.0796
[Sat, 17 May 2025 08:12:26 INFO] epoch: 014 - iter: 00400 - train loss: 0.7574 - time elapsed/per batch: 13.5570 0.0678
[Sat, 17 May 2025 08:12:41 INFO] epoch: 014 - iter: 00600 - train loss: 0.7808 - time elapsed/per batch: 14.8035 0.0740
[Sat, 17 May 2025 08:12:56 INFO] epoch: 014 - iter: 00800 - train loss: 0.7714 - time elapsed/per batch: 14.9380 0.0747
[Sat, 17 May 2025 08:13:09 INFO] epoch: 014 - iter: 01000 - train loss: 0.7832 - time elapsed/per batch: 13.6360 0.0682
[Sat, 17 May 2025 08:13:23 INFO] epoch: 014 - iter: 01200 - train loss: 0.7824 - time elapsed/per batch: 13.2060 0.0660
[Sat, 17 May 2025 08:13:38 INFO] epoch: 014 - iter: 01400 - train loss: 0.7518 - time elapsed/per batch: 15.6050 0.0780
[Sat, 17 May 2025 08:13:54 INFO] epoch: 014 - iter: 01600 - train loss: 0.7567 - time elapsed/per batch: 15.5248 0.0776
[Sat, 17 May 2025 08:14:08 INFO] epoch: 014 - iter: 01800 - train loss: 0.7827 - time elapsed/per batch: 14.3436 0.0717
[Sat, 17 May 2025 08:14:25 INFO] epoch: 014 - iter: 02000 - train loss: 0.7691 - time elapsed/per batch: 17.1141 0.0856
[Sat, 17 May 2025 08:14:44 INFO] epoch: 014 - iter: 02200 - train loss: 0.7552 - time elapsed/per batch: 19.2364 0.0962
[Sat, 17 May 2025 08:15:06 INFO] epoch: 014 - iter: 02400 - train loss: 0.7735 - time elapsed/per batch: 21.9898 0.1099
[Sat, 17 May 2025 08:15:28 INFO] epoch: 014 - iter: 02600 - train loss: 0.7539 - time elapsed/per batch: 22.0642 0.1103
[Sat, 17 May 2025 08:15:49 INFO] epoch: 014 - iter: 02800 - train loss: 0.7565 - time elapsed/per batch: 20.8510 0.1043
[Sat, 17 May 2025 08:16:09 INFO] epoch: 014 - iter: 03000 - train loss: 0.7575 - time elapsed/per batch: 19.4884 0.0974
[Sat, 17 May 2025 08:16:25 INFO] epoch: 014 - iter: 03200 - train loss: 0.7824 - time elapsed/per batch: 15.9834 0.0799
[Sat, 17 May 2025 08:16:44 INFO] epoch: 014 - iter: 03400 - train loss: 0.7521 - time elapsed/per batch: 19.5771 0.0979
[Sat, 17 May 2025 08:17:47 INFO] epoch: 014 - iter: 03600 - train loss: 0.7628 - time elapsed/per batch: 62.3952 0.3120
[Sat, 17 May 2025 08:18:11 INFO] epoch: 014 - iter: 03800 - train loss: 0.7601 - time elapsed/per batch: 24.6308 0.1232
[Sat, 17 May 2025 08:18:29 INFO] epoch: 014 - iter: 04000 - train loss: 0.7308 - time elapsed/per batch: 18.1562 0.0908
[Sat, 17 May 2025 08:18:49 INFO] epoch: 014 - iter: 04200 - train loss: 0.7585 - time elapsed/per batch: 19.4963 0.0975
[Sat, 17 May 2025 08:19:07 INFO] epoch: 014 - iter: 04400 - train loss: 0.7694 - time elapsed/per batch: 17.7481 0.0887
[Sat, 17 May 2025 08:19:24 INFO] epoch: 014 - iter: 04600 - train loss: 0.7923 - time elapsed/per batch: 17.1973 0.0860
[Sat, 17 May 2025 08:19:41 INFO] epoch: 014 - iter: 04800 - train loss: 0.7485 - time elapsed/per batch: 17.2820 0.0864
[Sat, 17 May 2025 08:19:57 INFO] epoch: 014 - iter: 05000 - train loss: 0.7640 - time elapsed/per batch: 15.3224 0.0766
[Sat, 17 May 2025 08:20:11 INFO] epoch: 014 - iter: 05200 - train loss: 0.7735 - time elapsed/per batch: 14.0935 0.0705
[Sat, 17 May 2025 08:20:27 INFO] epoch: 014 - iter: 05400 - train loss: 0.7629 - time elapsed/per batch: 16.3288 0.0816
[Sat, 17 May 2025 08:20:41 INFO] epoch: 014 - iter: 05600 - train loss: 0.7896 - time elapsed/per batch: 13.7654 0.0688
[Sat, 17 May 2025 08:21:19 INFO] epoch: 014 - iter: 05745 - valid loss: 3.4710 - bleu score: 0.1104 - full evaluation time: 28.3783
[Sat, 17 May 2025 08:21:36 INFO] epoch: 015 - iter: 00200 - train loss: 0.7496 - time elapsed/per batch: 16.3080 0.0815
[Sat, 17 May 2025 08:21:52 INFO] epoch: 015 - iter: 00400 - train loss: 0.7604 - time elapsed/per batch: 16.0513 0.0803
[Sat, 17 May 2025 08:22:08 INFO] epoch: 015 - iter: 00600 - train loss: 0.7513 - time elapsed/per batch: 16.3439 0.0817
[Sat, 17 May 2025 08:22:22 INFO] epoch: 015 - iter: 00800 - train loss: 0.7506 - time elapsed/per batch: 14.2201 0.0711
[Sat, 17 May 2025 08:22:38 INFO] epoch: 015 - iter: 01000 - train loss: 0.7473 - time elapsed/per batch: 15.6258 0.0781
[Sat, 17 May 2025 08:22:52 INFO] epoch: 015 - iter: 01200 - train loss: 0.7587 - time elapsed/per batch: 14.0264 0.0701
[Sat, 17 May 2025 08:23:06 INFO] epoch: 015 - iter: 01400 - train loss: 0.7658 - time elapsed/per batch: 14.2912 0.0715
[Sat, 17 May 2025 08:23:25 INFO] epoch: 015 - iter: 01600 - train loss: 0.7383 - time elapsed/per batch: 18.6022 0.0930
[Sat, 17 May 2025 08:23:39 INFO] epoch: 015 - iter: 01800 - train loss: 0.7656 - time elapsed/per batch: 14.1105 0.0706
[Sat, 17 May 2025 08:23:54 INFO] epoch: 015 - iter: 02000 - train loss: 0.7516 - time elapsed/per batch: 15.2336 0.0762
[Sat, 17 May 2025 08:24:08 INFO] epoch: 015 - iter: 02200 - train loss: 0.7758 - time elapsed/per batch: 14.3833 0.0719
[Sat, 17 May 2025 08:24:24 INFO] epoch: 015 - iter: 02400 - train loss: 0.7421 - time elapsed/per batch: 15.8272 0.0791
[Sat, 17 May 2025 08:24:38 INFO] epoch: 015 - iter: 02600 - train loss: 0.7475 - time elapsed/per batch: 14.1198 0.0706
[Sat, 17 May 2025 08:24:53 INFO] epoch: 015 - iter: 02800 - train loss: 0.7747 - time elapsed/per batch: 14.4492 0.0722
[Sat, 17 May 2025 08:25:08 INFO] epoch: 015 - iter: 03000 - train loss: 0.7724 - time elapsed/per batch: 15.0044 0.0750
[Sat, 17 May 2025 08:25:22 INFO] epoch: 015 - iter: 03200 - train loss: 0.7751 - time elapsed/per batch: 13.9543 0.0698
[Sat, 17 May 2025 08:25:36 INFO] epoch: 015 - iter: 03400 - train loss: 0.7828 - time elapsed/per batch: 13.6863 0.0684
[Sat, 17 May 2025 08:25:50 INFO] epoch: 015 - iter: 03600 - train loss: 0.7583 - time elapsed/per batch: 14.4437 0.0722
[Sat, 17 May 2025 08:26:04 INFO] epoch: 015 - iter: 03800 - train loss: 0.7700 - time elapsed/per batch: 14.0766 0.0704
[Sat, 17 May 2025 08:26:18 INFO] epoch: 015 - iter: 04000 - train loss: 0.7637 - time elapsed/per batch: 14.1650 0.0708
[Sat, 17 May 2025 08:26:34 INFO] epoch: 015 - iter: 04200 - train loss: 0.7443 - time elapsed/per batch: 15.4884 0.0774
[Sat, 17 May 2025 08:26:48 INFO] epoch: 015 - iter: 04400 - train loss: 0.7678 - time elapsed/per batch: 14.6522 0.0733
[Sat, 17 May 2025 08:27:03 INFO] epoch: 015 - iter: 04600 - train loss: 0.7291 - time elapsed/per batch: 14.8064 0.0740
[Sat, 17 May 2025 08:27:19 INFO] epoch: 015 - iter: 04800 - train loss: 0.7633 - time elapsed/per batch: 15.4693 0.0773
[Sat, 17 May 2025 08:27:33 INFO] epoch: 015 - iter: 05000 - train loss: 0.7538 - time elapsed/per batch: 14.4453 0.0722
[Sat, 17 May 2025 08:27:47 INFO] epoch: 015 - iter: 05200 - train loss: 0.7629 - time elapsed/per batch: 14.2339 0.0712
[Sat, 17 May 2025 08:28:02 INFO] epoch: 015 - iter: 05400 - train loss: 0.7449 - time elapsed/per batch: 14.3982 0.0720
[Sat, 17 May 2025 08:28:16 INFO] epoch: 015 - iter: 05600 - train loss: 0.7668 - time elapsed/per batch: 14.2044 0.0710
[Sat, 17 May 2025 08:28:56 INFO] epoch: 015 - iter: 05745 - valid loss: 3.4584 - bleu score: 0.1143 - full evaluation time: 30.0983
[Sat, 17 May 2025 08:29:11 INFO] epoch: 016 - iter: 00200 - train loss: 0.7512 - time elapsed/per batch: 14.2981 0.0715
[Sat, 17 May 2025 08:29:25 INFO] epoch: 016 - iter: 00400 - train loss: 0.7381 - time elapsed/per batch: 14.3295 0.0716
[Sat, 17 May 2025 08:29:41 INFO] epoch: 016 - iter: 00600 - train loss: 0.7502 - time elapsed/per batch: 16.3824 0.0819
[Sat, 17 May 2025 08:29:55 INFO] epoch: 016 - iter: 00800 - train loss: 0.7651 - time elapsed/per batch: 13.7580 0.0688
[Sat, 17 May 2025 08:30:13 INFO] epoch: 016 - iter: 01000 - train loss: 0.7539 - time elapsed/per batch: 18.2827 0.0914
[Sat, 17 May 2025 08:30:28 INFO] epoch: 016 - iter: 01200 - train loss: 0.7316 - time elapsed/per batch: 14.9694 0.0748
[Sat, 17 May 2025 08:30:44 INFO] epoch: 016 - iter: 01400 - train loss: 0.7725 - time elapsed/per batch: 15.6094 0.0780
[Sat, 17 May 2025 08:30:58 INFO] epoch: 016 - iter: 01600 - train loss: 0.7744 - time elapsed/per batch: 14.0919 0.0705
[Sat, 17 May 2025 08:31:14 INFO] epoch: 016 - iter: 01800 - train loss: 0.7357 - time elapsed/per batch: 15.7883 0.0789
[Sat, 17 May 2025 08:31:28 INFO] epoch: 016 - iter: 02000 - train loss: 0.7592 - time elapsed/per batch: 14.0673 0.0703
[Sat, 17 May 2025 08:31:42 INFO] epoch: 016 - iter: 02200 - train loss: 0.7709 - time elapsed/per batch: 14.0739 0.0704
[Sat, 17 May 2025 08:31:56 INFO] epoch: 016 - iter: 02400 - train loss: 0.7340 - time elapsed/per batch: 14.3744 0.0719
[Sat, 17 May 2025 08:32:11 INFO] epoch: 016 - iter: 02600 - train loss: 0.7196 - time elapsed/per batch: 14.7969 0.0740
[Sat, 17 May 2025 08:32:26 INFO] epoch: 016 - iter: 02800 - train loss: 0.7383 - time elapsed/per batch: 14.7796 0.0739
[Sat, 17 May 2025 08:32:40 INFO] epoch: 016 - iter: 03000 - train loss: 0.7449 - time elapsed/per batch: 13.9200 0.0696
[Sat, 17 May 2025 08:32:55 INFO] epoch: 016 - iter: 03200 - train loss: 0.7405 - time elapsed/per batch: 15.5040 0.0775
[Sat, 17 May 2025 08:33:10 INFO] epoch: 016 - iter: 03400 - train loss: 0.7603 - time elapsed/per batch: 14.3455 0.0717
[Sat, 17 May 2025 08:33:25 INFO] epoch: 016 - iter: 03600 - train loss: 0.7440 - time elapsed/per batch: 14.9265 0.0746
[Sat, 17 May 2025 08:33:41 INFO] epoch: 016 - iter: 03800 - train loss: 0.7688 - time elapsed/per batch: 15.9031 0.0795
[Sat, 17 May 2025 08:33:57 INFO] epoch: 016 - iter: 04000 - train loss: 0.7466 - time elapsed/per batch: 16.2320 0.0812
[Sat, 17 May 2025 08:34:11 INFO] epoch: 016 - iter: 04200 - train loss: 0.7565 - time elapsed/per batch: 14.2913 0.0715
[Sat, 17 May 2025 08:34:25 INFO] epoch: 016 - iter: 04400 - train loss: 0.7500 - time elapsed/per batch: 14.1801 0.0709
[Sat, 17 May 2025 08:34:40 INFO] epoch: 016 - iter: 04600 - train loss: 0.7758 - time elapsed/per batch: 15.2030 0.0760
[Sat, 17 May 2025 08:34:55 INFO] epoch: 016 - iter: 04800 - train loss: 0.7520 - time elapsed/per batch: 14.5193 0.0726
[Sat, 17 May 2025 08:35:09 INFO] epoch: 016 - iter: 05000 - train loss: 0.7694 - time elapsed/per batch: 14.0960 0.0705
[Sat, 17 May 2025 08:35:24 INFO] epoch: 016 - iter: 05200 - train loss: 0.7213 - time elapsed/per batch: 14.7650 0.0738
[Sat, 17 May 2025 08:35:38 INFO] epoch: 016 - iter: 05400 - train loss: 0.7320 - time elapsed/per batch: 14.4143 0.0721
[Sat, 17 May 2025 08:35:53 INFO] epoch: 016 - iter: 05600 - train loss: 0.7683 - time elapsed/per batch: 14.2154 0.0711
[Sat, 17 May 2025 08:36:34 INFO] epoch: 016 - iter: 05745 - valid loss: 3.4553 - bleu score: 0.1149 - full evaluation time: 30.2200
[Sat, 17 May 2025 08:36:48 INFO] epoch: 017 - iter: 00200 - train loss: 0.7462 - time elapsed/per batch: 14.1627 0.0708
[Sat, 17 May 2025 08:37:04 INFO] epoch: 017 - iter: 00400 - train loss: 0.7310 - time elapsed/per batch: 16.6616 0.0833
[Sat, 17 May 2025 08:37:18 INFO] epoch: 017 - iter: 00600 - train loss: 0.7622 - time elapsed/per batch: 13.6261 0.0681
[Sat, 17 May 2025 08:37:33 INFO] epoch: 017 - iter: 00800 - train loss: 0.7314 - time elapsed/per batch: 14.7913 0.0740
[Sat, 17 May 2025 08:37:48 INFO] epoch: 017 - iter: 01000 - train loss: 0.7405 - time elapsed/per batch: 15.1535 0.0758
[Sat, 17 May 2025 08:38:02 INFO] epoch: 017 - iter: 01200 - train loss: 0.7280 - time elapsed/per batch: 14.3586 0.0718
[Sat, 17 May 2025 08:38:16 INFO] epoch: 017 - iter: 01400 - train loss: 0.7630 - time elapsed/per batch: 13.9427 0.0697
[Sat, 17 May 2025 08:38:30 INFO] epoch: 017 - iter: 01600 - train loss: 0.7699 - time elapsed/per batch: 13.7911 0.0690
[Sat, 17 May 2025 08:38:46 INFO] epoch: 017 - iter: 01800 - train loss: 0.7505 - time elapsed/per batch: 15.8227 0.0791
[Sat, 17 May 2025 08:39:02 INFO] epoch: 017 - iter: 02000 - train loss: 0.7481 - time elapsed/per batch: 16.2915 0.0815
[Sat, 17 May 2025 08:39:17 INFO] epoch: 017 - iter: 02200 - train loss: 0.7338 - time elapsed/per batch: 14.4272 0.0721
[Sat, 17 May 2025 08:39:31 INFO] epoch: 017 - iter: 02400 - train loss: 0.7556 - time elapsed/per batch: 14.5594 0.0728
[Sat, 17 May 2025 08:39:45 INFO] epoch: 017 - iter: 02600 - train loss: 0.7445 - time elapsed/per batch: 14.0106 0.0701
[Sat, 17 May 2025 08:39:59 INFO] epoch: 017 - iter: 02800 - train loss: 0.7670 - time elapsed/per batch: 14.1773 0.0709
[Sat, 17 May 2025 08:40:15 INFO] epoch: 017 - iter: 03000 - train loss: 0.7324 - time elapsed/per batch: 15.7032 0.0785
[Sat, 17 May 2025 08:40:31 INFO] epoch: 017 - iter: 03200 - train loss: 0.7435 - time elapsed/per batch: 16.1155 0.0806
[Sat, 17 May 2025 08:40:46 INFO] epoch: 017 - iter: 03400 - train loss: 0.7611 - time elapsed/per batch: 15.0177 0.0751
[Sat, 17 May 2025 08:41:02 INFO] epoch: 017 - iter: 03600 - train loss: 0.7668 - time elapsed/per batch: 16.1161 0.0806
[Sat, 17 May 2025 08:41:18 INFO] epoch: 017 - iter: 03800 - train loss: 0.7248 - time elapsed/per batch: 15.4078 0.0770
[Sat, 17 May 2025 08:41:31 INFO] epoch: 017 - iter: 04000 - train loss: 0.7574 - time elapsed/per batch: 13.7693 0.0688
[Sat, 17 May 2025 08:41:46 INFO] epoch: 017 - iter: 04200 - train loss: 0.7476 - time elapsed/per batch: 14.7064 0.0735
[Sat, 17 May 2025 08:42:02 INFO] epoch: 017 - iter: 04400 - train loss: 0.7849 - time elapsed/per batch: 15.6965 0.0785
[Sat, 17 May 2025 08:42:16 INFO] epoch: 017 - iter: 04600 - train loss: 0.7404 - time elapsed/per batch: 14.0063 0.0700
[Sat, 17 May 2025 08:42:30 INFO] epoch: 017 - iter: 04800 - train loss: 0.7493 - time elapsed/per batch: 14.3704 0.0719
[Sat, 17 May 2025 08:42:45 INFO] epoch: 017 - iter: 05000 - train loss: 0.7424 - time elapsed/per batch: 14.5756 0.0729
[Sat, 17 May 2025 08:42:59 INFO] epoch: 017 - iter: 05200 - train loss: 0.7374 - time elapsed/per batch: 14.2945 0.0715
[Sat, 17 May 2025 08:43:13 INFO] epoch: 017 - iter: 05400 - train loss: 0.7620 - time elapsed/per batch: 14.3193 0.0716
[Sat, 17 May 2025 08:43:28 INFO] epoch: 017 - iter: 05600 - train loss: 0.7385 - time elapsed/per batch: 14.7343 0.0737
[Sat, 17 May 2025 08:44:07 INFO] epoch: 017 - iter: 05745 - valid loss: 3.4470 - bleu score: 0.1179 - full evaluation time: 28.1963
[Sat, 17 May 2025 08:44:21 INFO] epoch: 018 - iter: 00200 - train loss: 0.7311 - time elapsed/per batch: 14.3474 0.0717
[Sat, 17 May 2025 08:44:38 INFO] epoch: 018 - iter: 00400 - train loss: 0.7181 - time elapsed/per batch: 16.6306 0.0832
[Sat, 17 May 2025 08:44:52 INFO] epoch: 018 - iter: 00600 - train loss: 0.7440 - time elapsed/per batch: 14.0973 0.0705
[Sat, 17 May 2025 08:45:06 INFO] epoch: 018 - iter: 00800 - train loss: 0.7293 - time elapsed/per batch: 14.1259 0.0706
[Sat, 17 May 2025 08:45:20 INFO] epoch: 018 - iter: 01000 - train loss: 0.7620 - time elapsed/per batch: 13.9533 0.0698
[Sat, 17 May 2025 08:45:34 INFO] epoch: 018 - iter: 01200 - train loss: 0.7495 - time elapsed/per batch: 13.9852 0.0699
[Sat, 17 May 2025 08:45:48 INFO] epoch: 018 - iter: 01400 - train loss: 0.7526 - time elapsed/per batch: 13.9326 0.0697
[Sat, 17 May 2025 08:46:02 INFO] epoch: 018 - iter: 01600 - train loss: 0.7360 - time elapsed/per batch: 14.1139 0.0706
[Sat, 17 May 2025 08:46:18 INFO] epoch: 018 - iter: 01800 - train loss: 0.7381 - time elapsed/per batch: 16.2712 0.0814
[Sat, 17 May 2025 08:46:32 INFO] epoch: 018 - iter: 02000 - train loss: 0.7712 - time elapsed/per batch: 14.0365 0.0702
[Sat, 17 May 2025 08:46:46 INFO] epoch: 018 - iter: 02200 - train loss: 0.7399 - time elapsed/per batch: 13.6298 0.0681
[Sat, 17 May 2025 08:47:02 INFO] epoch: 018 - iter: 02400 - train loss: 0.7223 - time elapsed/per batch: 15.9417 0.0797
[Sat, 17 May 2025 08:47:16 INFO] epoch: 018 - iter: 02600 - train loss: 0.7396 - time elapsed/per batch: 14.0781 0.0704
[Sat, 17 May 2025 08:47:30 INFO] epoch: 018 - iter: 02800 - train loss: 0.7667 - time elapsed/per batch: 13.9103 0.0696
[Sat, 17 May 2025 08:47:44 INFO] epoch: 018 - iter: 03000 - train loss: 0.7330 - time elapsed/per batch: 14.2270 0.0711
[Sat, 17 May 2025 08:48:02 INFO] epoch: 018 - iter: 03200 - train loss: 0.7281 - time elapsed/per batch: 17.6384 0.0882
[Sat, 17 May 2025 08:48:16 INFO] epoch: 018 - iter: 03400 - train loss: 0.7269 - time elapsed/per batch: 14.3550 0.0718
[Sat, 17 May 2025 08:48:30 INFO] epoch: 018 - iter: 03600 - train loss: 0.7574 - time elapsed/per batch: 13.9357 0.0697
[Sat, 17 May 2025 08:48:44 INFO] epoch: 018 - iter: 03800 - train loss: 0.7701 - time elapsed/per batch: 14.1883 0.0709
[Sat, 17 May 2025 08:48:58 INFO] epoch: 018 - iter: 04000 - train loss: 0.7596 - time elapsed/per batch: 13.8619 0.0693
[Sat, 17 May 2025 08:49:14 INFO] epoch: 018 - iter: 04200 - train loss: 0.7221 - time elapsed/per batch: 16.1209 0.0806
[Sat, 17 May 2025 08:49:28 INFO] epoch: 018 - iter: 04400 - train loss: 0.7463 - time elapsed/per batch: 13.8665 0.0693
[Sat, 17 May 2025 08:49:44 INFO] epoch: 018 - iter: 04600 - train loss: 0.7213 - time elapsed/per batch: 15.7365 0.0787
[Sat, 17 May 2025 08:49:58 INFO] epoch: 018 - iter: 04800 - train loss: 0.7418 - time elapsed/per batch: 14.3844 0.0719
[Sat, 17 May 2025 08:50:15 INFO] epoch: 018 - iter: 05000 - train loss: 0.7768 - time elapsed/per batch: 16.4540 0.0823
[Sat, 17 May 2025 08:50:31 INFO] epoch: 018 - iter: 05200 - train loss: 0.7390 - time elapsed/per batch: 16.6976 0.0835
[Sat, 17 May 2025 08:50:49 INFO] epoch: 018 - iter: 05400 - train loss: 0.7383 - time elapsed/per batch: 18.0439 0.0902
[Sat, 17 May 2025 08:51:08 INFO] epoch: 018 - iter: 05600 - train loss: 0.7325 - time elapsed/per batch: 18.8370 0.0942
[Sat, 17 May 2025 08:51:53 INFO] epoch: 018 - iter: 05745 - valid loss: 3.4381 - bleu score: 0.1170 - full evaluation time: 30.6756
[Sat, 17 May 2025 08:52:09 INFO] epoch: 019 - iter: 00200 - train loss: 0.7148 - time elapsed/per batch: 15.5887 0.0779
[Sat, 17 May 2025 08:52:25 INFO] epoch: 019 - iter: 00400 - train loss: 0.7131 - time elapsed/per batch: 15.9068 0.0795
[Sat, 17 May 2025 08:52:39 INFO] epoch: 019 - iter: 00600 - train loss: 0.7311 - time elapsed/per batch: 14.5377 0.0727
[Sat, 17 May 2025 08:52:53 INFO] epoch: 019 - iter: 00800 - train loss: 0.7429 - time elapsed/per batch: 14.2307 0.0712
[Sat, 17 May 2025 08:53:15 INFO] epoch: 019 - iter: 01000 - train loss: 0.7390 - time elapsed/per batch: 21.0971 0.1055
[Sat, 17 May 2025 08:53:29 INFO] epoch: 019 - iter: 01200 - train loss: 0.7426 - time elapsed/per batch: 14.8437 0.0742
[Sat, 17 May 2025 08:53:44 INFO] epoch: 019 - iter: 01400 - train loss: 0.7153 - time elapsed/per batch: 14.4541 0.0723
[Sat, 17 May 2025 08:53:57 INFO] epoch: 019 - iter: 01600 - train loss: 0.7566 - time elapsed/per batch: 13.6682 0.0683
[Sat, 17 May 2025 08:54:12 INFO] epoch: 019 - iter: 01800 - train loss: 0.7312 - time elapsed/per batch: 14.0603 0.0703
[Sat, 17 May 2025 08:54:26 INFO] epoch: 019 - iter: 02000 - train loss: 0.7479 - time elapsed/per batch: 14.1987 0.0710
[Sat, 17 May 2025 08:54:40 INFO] epoch: 019 - iter: 02200 - train loss: 0.7219 - time elapsed/per batch: 13.8844 0.0694
[Sat, 17 May 2025 08:54:54 INFO] epoch: 019 - iter: 02400 - train loss: 0.7159 - time elapsed/per batch: 14.3623 0.0718
[Sat, 17 May 2025 08:55:07 INFO] epoch: 019 - iter: 02600 - train loss: 0.7662 - time elapsed/per batch: 13.4088 0.0670
[Sat, 17 May 2025 08:55:21 INFO] epoch: 019 - iter: 02800 - train loss: 0.7464 - time elapsed/per batch: 13.6248 0.0681
[Sat, 17 May 2025 08:55:35 INFO] epoch: 019 - iter: 03000 - train loss: 0.7570 - time elapsed/per batch: 13.5674 0.0678
[Sat, 17 May 2025 08:55:50 INFO] epoch: 019 - iter: 03200 - train loss: 0.7355 - time elapsed/per batch: 15.3344 0.0767
[Sat, 17 May 2025 08:56:06 INFO] epoch: 019 - iter: 03400 - train loss: 0.7601 - time elapsed/per batch: 16.0106 0.0801
[Sat, 17 May 2025 08:56:20 INFO] epoch: 019 - iter: 03600 - train loss: 0.7502 - time elapsed/per batch: 14.1113 0.0706
[Sat, 17 May 2025 08:56:36 INFO] epoch: 019 - iter: 03800 - train loss: 0.7293 - time elapsed/per batch: 16.1311 0.0807
[Sat, 17 May 2025 08:56:51 INFO] epoch: 019 - iter: 04000 - train loss: 0.7530 - time elapsed/per batch: 15.2108 0.0761
[Sat, 17 May 2025 08:57:05 INFO] epoch: 019 - iter: 04200 - train loss: 0.7429 - time elapsed/per batch: 13.9431 0.0697
[Sat, 17 May 2025 08:57:20 INFO] epoch: 019 - iter: 04400 - train loss: 0.7318 - time elapsed/per batch: 14.2881 0.0714
[Sat, 17 May 2025 08:57:36 INFO] epoch: 019 - iter: 04600 - train loss: 0.7417 - time elapsed/per batch: 16.6432 0.0832
[Sat, 17 May 2025 08:57:52 INFO] epoch: 019 - iter: 04800 - train loss: 0.7660 - time elapsed/per batch: 15.2898 0.0764
[Sat, 17 May 2025 08:58:08 INFO] epoch: 019 - iter: 05000 - train loss: 0.7443 - time elapsed/per batch: 16.7686 0.0838
[Sat, 17 May 2025 08:58:22 INFO] epoch: 019 - iter: 05200 - train loss: 0.7555 - time elapsed/per batch: 13.5133 0.0676
[Sat, 17 May 2025 08:58:36 INFO] epoch: 019 - iter: 05400 - train loss: 0.7186 - time elapsed/per batch: 14.5678 0.0728
[Sat, 17 May 2025 08:58:51 INFO] epoch: 019 - iter: 05600 - train loss: 0.7115 - time elapsed/per batch: 14.5372 0.0727
[Sat, 17 May 2025 08:59:30 INFO] epoch: 019 - iter: 05745 - valid loss: 3.4394 - bleu score: 0.1200 - full evaluation time: 28.4539
